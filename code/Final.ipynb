{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first: importing all relevant libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "import scipy.stats\n",
    "from sklearn.linear_model import Ridge\n",
    "import my_repository as my\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def rmsle(y_true, y_pred, y_type=None):\n",
    "    n = len(y_true)\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    parcels = [(np.log(y_pred[i] + 1) - np.log(y_true[i] + 1))**2 for i in xrange(n)]\n",
    "    return np.sqrt(np.sum(parcels) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('../data/train.csv')\n",
    "data = original_data.copy()\n",
    "original_test = pd.read_csv('../data/test.csv')\n",
    "test = original_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following features have missing values. How much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataNaN = data.isnull().sum()\n",
    "dataNaN = dataNaN[dataNaN > 0]\n",
    "testNaN = test.isnull().sum()\n",
    "testNaN = testNaN[testNaN > 0]\n",
    "\n",
    "#print dataNaN\n",
    "#print testNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.boxplot('LotFrontage', by='Neighborhood', figsize=(16, 7), fontsize=8)\n",
    "#test.boxplot('LotFrontage', by='Neighborhood', figsize=(16, 7), fontsize=8)\n",
    "#data.boxplot('LotArea', by='Neighborhood', figsize=(16, 7), fontsize=8)\n",
    "#test.boxplot('LotArea', by='Neighborhood', figsize=(16, 7), fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.plot(x='LotFrontage', y='SalePrice', kind='scatter', figsize=(3, 3), fontsize=5)\n",
    "#data.plot(x='LotArea', y='SalePrice', kind='scatter', figsize=(3, 3), fontsize=5)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(set(data['Neighborhood']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(5,5, figsize=(25,25))\n",
    "#for (neigh, group), ax in zip(data.groupby('Neighborhood'), axes.flatten()):\n",
    "#    group.plot(x='LotFrontage', y='SalePrice', kind='scatter', ax=ax, title=neigh, fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#neighs = list(data['Neighborhood'].unique())\n",
    "#neighs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.groupby('Neighborhood')[['LotFrontage','SalePrice']].corr().ix[0::2,'SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.groupby('Neighborhood')[['LotArea','SalePrice']].corr().ix[0::2,'SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'm going to do two things:  \n",
    "\n",
    "First, treatment of missing values. For numeric variables, a missing value will receive the mean value of its variable over its Neighborhood. For categorical variables, it will simply receive \"N/A\".  \n",
    "\n",
    "Second, use one-hot encoding to transform categorical variables into several binary variables. Then, drop the original categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropfeatures = ['Id', 'GarageYrBlt']#, 'YrSold', 'YearBuilt', 'YearRemodAdd'\n",
    "\n",
    "for neigh in set(data['Neighborhood']):\n",
    "    value = data[data['Neighborhood'] == neigh]['LotFrontage'].median()\n",
    "    data.loc[(data['Neighborhood'] == neigh) & (data['LotFrontage'].isnull()), 'LotFrontage'] = value\n",
    "    value = data[data['Neighborhood'] == neigh]['MasVnrArea'].median()\n",
    "    data.loc[(data['Neighborhood'] == neigh) & (data['MasVnrArea'].isnull()), 'MasVnrArea'] = value\n",
    "data['MSSubClass'] = data['MSSubClass'].astype(str)\n",
    "data = data.fillna('N/A')\n",
    "dataId = data['Id']\n",
    "prices = data['SalePrice']\n",
    "features = data.drop(dropfeatures, axis=1)\n",
    "features = features.drop('SalePrice', axis=1)\n",
    "features_before_dummies = features\n",
    "features = pd.get_dummies(features) #, drop_first=True)\n",
    "\n",
    "tlist = ['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageArea',\n",
    "         'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'LotFrontage']\n",
    "for neigh in set(test['Neighborhood']):\n",
    "    for feature in tlist:\n",
    "        value = test[test['Neighborhood'] == neigh][feature].median()\n",
    "        test.loc[(test['Neighborhood'] == neigh) & (test[feature].isnull()), feature] = value\n",
    "test[tlist] = test[tlist].fillna(test[tlist].mean())\n",
    "test = test.fillna('N/A')\n",
    "test_id = test['Id']\n",
    "test_features = test.drop(dropfeatures, axis=1)\n",
    "test_features['MSSubClass'] = test_features['MSSubClass'].astype(str)\n",
    "test_features_before_dummies = test_features\n",
    "test_features = pd.get_dummies(test_features) #, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n",
      "(1460, 317)\n",
      "(1459, 306)\n"
     ]
    }
   ],
   "source": [
    "dataNaN = data.isnull().sum()\n",
    "dataNaN = dataNaN[dataNaN > 0]\n",
    "testNaN = test.isnull().sum()\n",
    "testNaN = testNaN[testNaN > 0]\n",
    "\n",
    "print dataNaN\n",
    "print testNaN\n",
    "print features.shape\n",
    "print test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are data features not present in test_features and vice-versa... This is because of categorical values present in one set and not on the other set. Let's drop the ones which are not present on both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 298)\n",
      "(1459, 298)\n"
     ]
    }
   ],
   "source": [
    "dropfeat = list(set(features).difference(set(test_features)))\n",
    "features = features.drop(dropfeat, axis=1)\n",
    "dropfeat = list(set(test_features).difference(set(features)))\n",
    "test_features = test_features.drop(dropfeat, axis=1)\n",
    "print features.shape\n",
    "print test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "dataNaN = features.isnull().sum()\n",
    "dataNaN = dataNaN[dataNaN > 0]\n",
    "testNaN = test_features.isnull().sum()\n",
    "testNaN = testNaN[testNaN > 0]\n",
    "print dataNaN\n",
    "print testNaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the fun begins. Let's do a log transform on our target variable, randomly partition the training set in 5 folds and prepare a data frame to contain the scores of every model which will be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logSalePrice = np.log1p(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(features), n_folds=5, shuffle=True, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_scores = pd.DataFrame(columns=['model', 'params', 'RMSLE'])\n",
    "model_scores_log = pd.DataFrame(columns=['model', 'params', 'RMSLE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating/finding a Ridge Regression model, both for original SalesPrice and for the log-transformed variable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   19.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.16207, std: 0.01020, params: {'alpha': 3.5920544727318231}\n",
      "mean: -0.16782, std: 0.01114, params: {'alpha': 4.2676772213970429}\n",
      "mean: -0.16112, std: 0.01003, params: {'alpha': 3.4796173789068394}\n",
      "mean: -0.16317, std: 0.01039, params: {'alpha': 3.7209328690659516}\n",
      "mean: -0.17208, std: 0.01176, params: {'alpha': 4.7718523999977949}\n",
      "mean: -0.16013, std: 0.02430, params: {'alpha': 0.35970502606340787}\n",
      "mean: -0.15111, std: 0.00794, params: {'alpha': 2.2438621842966602}\n",
      "mean: -0.15053, std: 0.01144, params: {'alpha': 0.52942013086000017}\n",
      "mean: -0.14642, std: 0.00724, params: {'alpha': 0.76966423820969365}\n",
      "mean: -0.15455, std: 0.00874, params: {'alpha': 2.6879116371049303}\n",
      "mean: -0.14552, std: 0.00633, params: {'alpha': 1.2411634348720442}\n",
      "mean: -0.16382, std: 0.01050, params: {'alpha': 3.7975245934262558}\n",
      "mean: -0.14544, std: 0.00630, params: {'alpha': 1.2065924142907436}\n",
      "mean: -0.16209, std: 0.01020, params: {'alpha': 3.5939703351801122}\n",
      "mean: -0.14736, std: 0.00693, params: {'alpha': 1.6781720975853998}\n",
      "mean: -0.16503, std: 0.01070, params: {'alpha': 3.9400534350623668}\n",
      "mean: -0.16529, std: 0.03254, params: {'alpha': 0.32401154218985934}\n",
      "mean: -0.14597, std: 0.00686, params: {'alpha': 0.8304309720690275}\n",
      "mean: -0.14603, std: 0.00690, params: {'alpha': 0.82148225834099931}\n",
      "mean: -0.14628, std: 0.00659, params: {'alpha': 1.4640406748666421}\n",
      "mean: -0.15590, std: 0.01819, params: {'alpha': 0.4092106064228484}\n",
      "mean: -0.16314, std: 0.01039, params: {'alpha': 3.7184094249052948}\n",
      "mean: -0.14870, std: 0.00732, params: {'alpha': 1.8981642271867465}\n",
      "mean: -0.14549, std: 0.00632, params: {'alpha': 1.2282648350470922}\n",
      "mean: -0.17040, std: 0.01152, params: {'alpha': 4.573144086346062}\n",
      "mean: -0.17314, std: 0.01190, params: {'alpha': 4.8982308295711041}\n",
      "mean: -0.15549, std: 0.00894, params: {'alpha': 2.8041719572986148}\n",
      "mean: -0.14653, std: 0.00667, params: {'alpha': 1.5179196920340925}\n",
      "mean: -0.15746, std: 0.00934, params: {'alpha': 3.0439193084789347}\n",
      "mean: -0.14827, std: 0.00720, params: {'alpha': 1.8307460687879609}\n",
      "mean: -0.16960, std: 0.01141, params: {'alpha': 4.4778267747486531}\n",
      "mean: -0.15913, std: 0.00966, params: {'alpha': 3.2441012757551975}\n",
      "mean: -0.16681, std: 0.01098, params: {'alpha': 4.1487063457157465}\n",
      "mean: -0.15605, std: 0.00905, params: {'alpha': 2.8725234757529203}\n",
      "mean: -0.15122, std: 0.00797, params: {'alpha': 2.2585464278881702}\n",
      "mean: -0.16377, std: 0.01049, params: {'alpha': 3.7923218012044861}\n",
      "mean: -0.14963, std: 0.00757, params: {'alpha': 2.037102990218675}\n",
      "mean: -0.14781, std: 0.00855, params: {'alpha': 0.65328275655180146}\n",
      "mean: -0.16506, std: 0.01071, params: {'alpha': 3.9434069987251679}\n",
      "mean: -0.14577, std: 0.00641, params: {'alpha': 1.3312234488809054}\n",
      "mean: -0.14752, std: 0.00826, params: {'alpha': 0.67290799621395814}\n",
      "mean: -0.15375, std: 0.00856, params: {'alpha': 2.5878684512529118}\n",
      "mean: -0.14534, std: 0.00632, params: {'alpha': 1.0222673394000323}\n",
      "mean: -0.16719, std: 0.01104, params: {'alpha': 4.1937861262865743}\n",
      "mean: -0.14543, std: 0.00630, params: {'alpha': 1.1994322693085873}\n",
      "mean: -0.14678, std: 0.00675, params: {'alpha': 1.5709220826266488}\n",
      "mean: -0.15658, std: 0.00916, params: {'alpha': 2.9368617793350063}\n",
      "mean: -0.17013, std: 0.01148, params: {'alpha': 4.5411878324926827}\n",
      "mean: -0.16812, std: 0.01119, params: {'alpha': 4.303405206286528}\n",
      "mean: -0.15127, std: 0.00798, params: {'alpha': 2.2649852147551233}\n",
      "mean: -0.15042, std: 0.00777, params: {'alpha': 2.1493384623438541}\n",
      "mean: -0.15847, std: 0.02182, params: {'alpha': 0.3762364125919811}\n",
      "mean: -0.14752, std: 0.00698, params: {'alpha': 1.7063028476692745}\n",
      "mean: -0.14912, std: 0.00743, params: {'alpha': 1.962757628020702}\n",
      "mean: -0.16978, std: 0.01143, params: {'alpha': 4.4994625273859619}\n",
      "mean: -0.16550, std: 0.01078, params: {'alpha': 3.994841876184632}\n",
      "mean: -0.16491, std: 0.01068, params: {'alpha': 3.9255185505826216}\n",
      "mean: -0.15134, std: 0.00800, params: {'alpha': 2.2742578291546547}\n",
      "mean: -0.16509, std: 0.01071, params: {'alpha': 3.9473181485825615}\n",
      "mean: -0.15292, std: 0.00837, params: {'alpha': 2.4822482747622696}\n",
      "mean: -0.14536, std: 0.00628, params: {'alpha': 1.1543197788740844}\n",
      "mean: -0.16940, std: 0.01138, params: {'alpha': 4.4549203423677808}\n",
      "mean: -0.16280, std: 0.01033, params: {'alpha': 3.6783236588797297}\n",
      "mean: -0.16093, std: 0.01000, params: {'alpha': 3.4578421105577624}\n",
      "mean: -0.14647, std: 0.00665, params: {'alpha': 1.5058490734001915}\n",
      "mean: -0.15172, std: 0.00809, params: {'alpha': 2.324768565580535}\n",
      "mean: -0.15837, std: 0.02168, params: {'alpha': 0.37733180939640787}\n",
      "mean: -0.14603, std: 0.00650, params: {'alpha': 1.4044709856520461}\n",
      "mean: -0.15467, std: 0.00876, params: {'alpha': 2.702505162482614}\n",
      "mean: -0.14733, std: 0.00692, params: {'alpha': 1.6724434299359563}\n",
      "mean: -0.15432, std: 0.00869, params: {'alpha': 2.6588994882169965}\n",
      "mean: -0.15418, std: 0.00866, params: {'alpha': 2.6418837105831767}\n",
      "mean: -0.14627, std: 0.00711, params: {'alpha': 0.78772616350967339}\n",
      "mean: -0.15227, std: 0.00822, params: {'alpha': 2.3982826424699271}\n",
      "mean: -0.17278, std: 0.01186, params: {'alpha': 4.8551890916376221}\n",
      "mean: -0.16359, std: 0.01046, params: {'alpha': 3.7708142713829393}\n",
      "mean: -0.16283, std: 0.01033, params: {'alpha': 3.6818878565802771}\n",
      "mean: -0.16976, std: 0.01143, params: {'alpha': 4.4973039165544044}\n",
      "mean: -0.17252, std: 0.01182, params: {'alpha': 4.8245710019060137}\n",
      "mean: -0.14548, std: 0.00632, params: {'alpha': 1.2261360708639721}\n",
      "mean: -0.16264, std: 0.01030, params: {'alpha': 3.6585728318316351}\n",
      "mean: -0.14531, std: 0.00629, params: {'alpha': 1.0610425146177764}\n",
      "mean: -0.16870, std: 0.01127, params: {'alpha': 4.3713974271093461}\n",
      "mean: -0.15903, std: 0.00964, params: {'alpha': 3.2319551620825679}\n",
      "mean: -0.17239, std: 0.01180, params: {'alpha': 4.8094390805744052}\n",
      "mean: -0.15516, std: 0.00887, params: {'alpha': 2.7634675984153931}\n",
      "mean: -0.15260, std: 0.01390, params: {'alpha': 0.47123452730547677}\n",
      "mean: -0.16313, std: 0.01038, params: {'alpha': 3.7162964192505479}\n",
      "mean: -0.16644, std: 0.03448, params: {'alpha': 0.31837626617855419}\n",
      "mean: -0.15032, std: 0.01121, params: {'alpha': 0.53638180552121706}\n",
      "mean: -0.17367, std: 0.01198, params: {'alpha': 4.9623638846136169}\n",
      "mean: -0.14567, std: 0.00638, params: {'alpha': 1.2976102516358883}\n",
      "mean: -0.17192, std: 0.01174, params: {'alpha': 4.7526421249093902}\n",
      "mean: -0.15246, std: 0.00827, params: {'alpha': 2.4222405794071098}\n",
      "mean: -0.17394, std: 0.01201, params: {'alpha': 4.9943349619799537}\n",
      "mean: -0.15997, std: 0.00982, params: {'alpha': 3.3432569989696614}\n",
      "mean: -0.16214, std: 0.01021, params: {'alpha': 3.6005313363325953}\n",
      "mean: -0.15167, std: 0.00808, params: {'alpha': 2.3190342975684612}\n",
      "mean: -0.14531, std: 0.00628, params: {'alpha': 1.0885413712586016}\n",
      "mean: -0.14583, std: 0.00674, params: {'alpha': 0.85522553935712708}\n",
      " \n",
      "Best valid score (RMSLE):  0.145311986171\n",
      "Full data training score:  0.125283615816\n",
      "{'alpha': 1.0885413712586016}\n",
      "\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   21.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.16634, std: 0.00969, params: {'alpha': 3.5920544727318231}\n",
      "mean: -0.17176, std: 0.01011, params: {'alpha': 4.2676772213970429}\n",
      "mean: -0.16542, std: 0.00964, params: {'alpha': 3.4796173789068394}\n",
      "mean: -0.16738, std: 0.00976, params: {'alpha': 3.7209328690659516}\n",
      "mean: -0.17571, std: 0.01050, params: {'alpha': 4.7718523999977949}\n",
      "mean: -0.14469, std: 0.01621, params: {'alpha': 0.35970502606340787}\n",
      "mean: -0.15521, std: 0.00986, params: {'alpha': 2.2438621842966602}\n",
      "mean: -0.14420, std: 0.01500, params: {'alpha': 0.52942013086000017}\n",
      "mean: -0.14472, std: 0.01368, params: {'alpha': 0.76966423820969365}\n",
      "mean: -0.15889, std: 0.00958, params: {'alpha': 2.6879116371049303}\n",
      "mean: -0.14740, std: 0.01184, params: {'alpha': 1.2411634348720442}\n",
      "mean: -0.16800, std: 0.00980, params: {'alpha': 3.7975245934262558}\n",
      "mean: -0.14716, std: 0.01195, params: {'alpha': 1.2065924142907436}\n",
      "mean: -0.16635, std: 0.00969, params: {'alpha': 3.5939703351801122}\n",
      "mean: -0.15064, std: 0.01071, params: {'alpha': 1.6781720975853998}\n",
      "mean: -0.16915, std: 0.00988, params: {'alpha': 3.9400534350623668}\n",
      "mean: -0.14495, std: 0.01651, params: {'alpha': 0.32401154218985934}\n",
      "mean: -0.14497, std: 0.01340, params: {'alpha': 0.8304309720690275}\n",
      "mean: -0.14493, std: 0.01344, params: {'alpha': 0.82148225834099931}\n",
      "mean: -0.14900, std: 0.01120, params: {'alpha': 1.4640406748666421}\n",
      "mean: -0.14443, std: 0.01582, params: {'alpha': 0.4092106064228484}\n",
      "mean: -0.16736, std: 0.00975, params: {'alpha': 3.7184094249052948}\n",
      "mean: -0.15239, std: 0.01030, params: {'alpha': 1.8981642271867465}\n",
      "mean: -0.14731, std: 0.01188, params: {'alpha': 1.2282648350470922}\n",
      "mean: -0.17417, std: 0.01034, params: {'alpha': 4.573144086346062}\n",
      "mean: -0.17669, std: 0.01060, params: {'alpha': 4.8982308295711041}\n",
      "mean: -0.15985, std: 0.00955, params: {'alpha': 2.8041719572986148}\n",
      "mean: -0.14941, std: 0.01107, params: {'alpha': 1.5179196920340925}\n",
      "mean: -0.16184, std: 0.00954, params: {'alpha': 3.0439193084789347}\n",
      "mean: -0.15185, std: 0.01042, params: {'alpha': 1.8307460687879609}\n",
      "mean: -0.17342, std: 0.01027, params: {'alpha': 4.4778267747486531}\n",
      "mean: -0.16349, std: 0.00957, params: {'alpha': 3.2441012757551975}\n",
      "mean: -0.17082, std: 0.01002, params: {'alpha': 4.1487063457157465}\n",
      "mean: -0.16042, std: 0.00954, params: {'alpha': 2.8725234757529203}\n",
      "mean: -0.15533, std: 0.00985, params: {'alpha': 2.2585464278881702}\n",
      "mean: -0.16796, std: 0.00979, params: {'alpha': 3.7923218012044861}\n",
      "mean: -0.15352, std: 0.01010, params: {'alpha': 2.037102990218675}\n",
      "mean: -0.14435, std: 0.01428, params: {'alpha': 0.65328275655180146}\n",
      "mean: -0.16918, std: 0.00989, params: {'alpha': 3.9434069987251679}\n",
      "mean: -0.14803, std: 0.01157, params: {'alpha': 1.3312234488809054}\n",
      "mean: -0.14440, std: 0.01417, params: {'alpha': 0.67290799621395814}\n",
      "mean: -0.15806, std: 0.00962, params: {'alpha': 2.5878684512529118}\n",
      "mean: -0.14599, std: 0.01260, params: {'alpha': 1.0222673394000323}\n",
      "mean: -0.17118, std: 0.01005, params: {'alpha': 4.1937861262865743}\n",
      "mean: -0.14711, std: 0.01198, params: {'alpha': 1.1994322693085873}\n",
      "mean: -0.14981, std: 0.01094, params: {'alpha': 1.5709220826266488}\n",
      "mean: -0.16095, std: 0.00953, params: {'alpha': 2.9368617793350063}\n",
      "mean: -0.17392, std: 0.01031, params: {'alpha': 4.5411878324926827}\n",
      "mean: -0.17205, std: 0.01013, params: {'alpha': 4.303405206286528}\n",
      "mean: -0.15539, std: 0.00984, params: {'alpha': 2.2649852147551233}\n",
      "mean: -0.15444, std: 0.00996, params: {'alpha': 2.1493384623438541}\n",
      "mean: -0.14459, std: 0.01608, params: {'alpha': 0.3762364125919811}\n",
      "mean: -0.15086, std: 0.01065, params: {'alpha': 1.7063028476692745}\n",
      "mean: -0.15291, std: 0.01020, params: {'alpha': 1.962757628020702}\n",
      "mean: -0.17359, std: 0.01028, params: {'alpha': 4.4994625273859619}\n",
      "mean: -0.16959, std: 0.00992, params: {'alpha': 3.994841876184632}\n",
      "mean: -0.16904, std: 0.00987, params: {'alpha': 3.9255185505826216}\n",
      "mean: -0.15546, std: 0.00983, params: {'alpha': 2.2742578291546547}\n",
      "mean: -0.16921, std: 0.00989, params: {'alpha': 3.9473181485825615}\n",
      "mean: -0.15718, std: 0.00967, params: {'alpha': 2.4822482747622696}\n",
      "mean: -0.14681, std: 0.01213, params: {'alpha': 1.1543197788740844}\n",
      "mean: -0.17324, std: 0.01025, params: {'alpha': 4.4549203423677808}\n",
      "mean: -0.16704, std: 0.00973, params: {'alpha': 3.6783236588797297}\n",
      "mean: -0.16524, std: 0.00963, params: {'alpha': 3.4578421105577624}\n",
      "mean: -0.14932, std: 0.01110, params: {'alpha': 1.5058490734001915}\n",
      "mean: -0.15588, std: 0.00979, params: {'alpha': 2.324768565580535}\n",
      "mean: -0.14458, std: 0.01607, params: {'alpha': 0.37733180939640787}\n",
      "mean: -0.14856, std: 0.01136, params: {'alpha': 1.4044709856520461}\n",
      "mean: -0.15901, std: 0.00957, params: {'alpha': 2.702505162482614}\n",
      "mean: -0.15060, std: 0.01072, params: {'alpha': 1.6724434299359563}\n",
      "mean: -0.15865, std: 0.00959, params: {'alpha': 2.6588994882169965}\n",
      "mean: -0.15851, std: 0.00960, params: {'alpha': 2.6418837105831767}\n",
      "mean: -0.14479, std: 0.01360, params: {'alpha': 0.78772616350967339}\n",
      "mean: -0.15649, std: 0.00973, params: {'alpha': 2.3982826424699271}\n",
      "mean: -0.17635, std: 0.01057, params: {'alpha': 4.8551890916376221}\n",
      "mean: -0.16779, std: 0.00978, params: {'alpha': 3.7708142713829393}\n",
      "mean: -0.16707, std: 0.00973, params: {'alpha': 3.6818878565802771}\n",
      "mean: -0.17357, std: 0.01028, params: {'alpha': 4.4973039165544044}\n",
      "mean: -0.17612, std: 0.01054, params: {'alpha': 4.8245710019060137}\n",
      "mean: -0.14729, std: 0.01189, params: {'alpha': 1.2261360708639721}\n",
      "mean: -0.16688, std: 0.00972, params: {'alpha': 3.6585728318316351}\n",
      "mean: -0.14622, std: 0.01246, params: {'alpha': 1.0610425146177764}\n",
      "mean: -0.17258, std: 0.01018, params: {'alpha': 4.3713974271093461}\n",
      "mean: -0.16339, std: 0.00956, params: {'alpha': 3.2319551620825679}\n",
      "mean: -0.17600, std: 0.01053, params: {'alpha': 4.8094390805744052}\n",
      "mean: -0.15952, std: 0.00956, params: {'alpha': 2.7634675984153931}\n",
      "mean: -0.14425, std: 0.01538, params: {'alpha': 0.47123452730547677}\n",
      "mean: -0.16735, std: 0.00975, params: {'alpha': 3.7162964192505479}\n",
      "mean: -0.14500, std: 0.01656, params: {'alpha': 0.31837626617855419}\n",
      "mean: -0.14420, std: 0.01495, params: {'alpha': 0.53638180552121706}\n",
      "mean: -0.17718, std: 0.01066, params: {'alpha': 4.9623638846136169}\n",
      "mean: -0.14779, std: 0.01167, params: {'alpha': 1.2976102516358883}\n",
      "mean: -0.17556, std: 0.01048, params: {'alpha': 4.7526421249093902}\n",
      "mean: -0.15669, std: 0.00971, params: {'alpha': 2.4222405794071098}\n",
      "mean: -0.17742, std: 0.01068, params: {'alpha': 4.9943349619799537}\n",
      "mean: -0.16430, std: 0.00959, params: {'alpha': 3.3432569989696614}\n",
      "mean: -0.16641, std: 0.00969, params: {'alpha': 3.6005313363325953}\n",
      "mean: -0.15583, std: 0.00979, params: {'alpha': 2.3190342975684612}\n",
      "mean: -0.14639, std: 0.01236, params: {'alpha': 1.0885413712586016}\n",
      "mean: -0.14509, std: 0.01329, params: {'alpha': 0.85522553935712708}\n",
      " \n",
      "Best valid score (RMSLE):  0.144198792523\n",
      "Full data training score:  0.114439144247\n",
      "{'alpha': 0.53638180552121706}\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge_def = Ridge(normalize=True, max_iter=50000, random_state=666)\n",
    "params = {'alpha': scipy.stats.uniform(loc=0.3, scale=5-0.3)}\n",
    "np.random.seed(666)\n",
    "ridge_model = my.make_model(features, prices, ridge_def, params, cv=kf, grid_type='random', n_iter=100, n_jobs=-1)\n",
    "np.random.seed(666)\n",
    "ridge_log_model = my.make_model(features, logSalePrice, ridge_def, params, cv=kf, y_type='log1p', grid_type='random', n_iter=100, n_jobs=-1)\n",
    "\n",
    "scores = pd.DataFrame([['Ridge', str(ridge_model.best_params_), -ridge_model.best_score_]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores = model_scores.append(scores)\n",
    "scores = pd.DataFrame([['Ridge', str(ridge_log_model.best_params_), -ridge_log_model.best_score_]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores_log = model_scores_log.append(scores)\n",
    "\n",
    "my.fit_submit(test_features, test_id, ridge_model, '../data/submissions/ridge.csv')\n",
    "my.fit_submit(test_features, test_id, ridge_log_model, '../data/submissions/ridge_log.csv', price_type='log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating/finding a Gradient Boosting model, both for original SalesPrice and for the log-transformed variable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 83.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 93.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.13463, std: 0.01367, params: {'min_samples_split': 15, 'loss': 'ls', 'n_estimators': 2000, 'max_depth': 5}\n",
      "mean: -0.13556, std: 0.01230, params: {'min_samples_split': 11, 'loss': 'ls', 'n_estimators': 2512, 'max_depth': 5}\n",
      "mean: -0.13074, std: 0.01111, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 2835, 'max_depth': 4}\n",
      "mean: -0.12977, std: 0.00898, params: {'min_samples_split': 16, 'loss': 'lad', 'n_estimators': 4634, 'max_depth': 3}\n",
      "mean: -0.13142, std: 0.00898, params: {'min_samples_split': 14, 'loss': 'lad', 'n_estimators': 4097, 'max_depth': 4}\n",
      "mean: -0.12806, std: 0.01086, params: {'min_samples_split': 13, 'loss': 'lad', 'n_estimators': 4170, 'max_depth': 4}\n",
      "mean: -0.13099, std: 0.01245, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 726, 'max_depth': 3}\n",
      "mean: -0.13266, std: 0.01332, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 2006, 'max_depth': 5}\n",
      "mean: -0.13138, std: 0.01249, params: {'min_samples_split': 12, 'loss': 'ls', 'n_estimators': 4819, 'max_depth': 4}\n",
      "mean: -0.13405, std: 0.01086, params: {'min_samples_split': 2, 'loss': 'ls', 'n_estimators': 192, 'max_depth': 5}\n",
      "mean: -0.13359, std: 0.01161, params: {'min_samples_split': 2, 'loss': 'ls', 'n_estimators': 2062, 'max_depth': 5}\n",
      "mean: -0.13064, std: 0.01008, params: {'min_samples_split': 4, 'loss': 'lad', 'n_estimators': 897, 'max_depth': 5}\n",
      "mean: -0.13359, std: 0.01169, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 107, 'max_depth': 5}\n",
      "mean: -0.13005, std: 0.01150, params: {'min_samples_split': 11, 'loss': 'lad', 'n_estimators': 1119, 'max_depth': 5}\n",
      "mean: -0.13335, std: 0.01447, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 2041, 'max_depth': 3}\n",
      "mean: -0.13135, std: 0.01121, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 1733, 'max_depth': 3}\n",
      "mean: -0.13332, std: 0.01251, params: {'min_samples_split': 5, 'loss': 'ls', 'n_estimators': 1207, 'max_depth': 4}\n",
      "mean: -0.12601, std: 0.00842, params: {'min_samples_split': 7, 'loss': 'lad', 'n_estimators': 2935, 'max_depth': 4}\n",
      "mean: -0.13206, std: 0.01277, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 195, 'max_depth': 3}\n",
      "mean: -0.12885, std: 0.00849, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 2526, 'max_depth': 5}\n",
      "mean: -0.13133, std: 0.01113, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 1884, 'max_depth': 3}\n",
      "mean: -0.13183, std: 0.01158, params: {'min_samples_split': 9, 'loss': 'ls', 'n_estimators': 3671, 'max_depth': 4}\n",
      "mean: -0.12927, std: 0.01003, params: {'min_samples_split': 4, 'loss': 'lad', 'n_estimators': 3092, 'max_depth': 3}\n",
      "mean: -0.13172, std: 0.01262, params: {'min_samples_split': 7, 'loss': 'ls', 'n_estimators': 1402, 'max_depth': 3}\n",
      "mean: -0.12597, std: 0.01184, params: {'min_samples_split': 19, 'loss': 'lad', 'n_estimators': 2108, 'max_depth': 4}\n",
      "mean: -0.13336, std: 0.01453, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 1957, 'max_depth': 3}\n",
      "mean: -0.13300, std: 0.01249, params: {'min_samples_split': 6, 'loss': 'ls', 'n_estimators': 594, 'max_depth': 4}\n",
      "mean: -0.12852, std: 0.01221, params: {'min_samples_split': 8, 'loss': 'lad', 'n_estimators': 4282, 'max_depth': 3}\n",
      "mean: -0.13000, std: 0.00937, params: {'min_samples_split': 10, 'loss': 'lad', 'n_estimators': 1066, 'max_depth': 5}\n",
      "mean: -0.12813, std: 0.00918, params: {'min_samples_split': 8, 'loss': 'lad', 'n_estimators': 4097, 'max_depth': 5}\n",
      "mean: -0.12913, std: 0.01004, params: {'min_samples_split': 11, 'loss': 'lad', 'n_estimators': 2060, 'max_depth': 4}\n",
      "mean: -0.13270, std: 0.01335, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 550, 'max_depth': 5}\n",
      "mean: -0.13248, std: 0.01061, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 4527, 'max_depth': 3}\n",
      "mean: -0.13230, std: 0.00890, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 3150, 'max_depth': 4}\n",
      "mean: -0.13174, std: 0.01192, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 2467, 'max_depth': 5}\n",
      "mean: -0.13156, std: 0.01081, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 1978, 'max_depth': 4}\n",
      "mean: -0.13272, std: 0.01278, params: {'min_samples_split': 11, 'loss': 'ls', 'n_estimators': 4047, 'max_depth': 3}\n",
      "mean: -0.12811, std: 0.00944, params: {'min_samples_split': 17, 'loss': 'lad', 'n_estimators': 3485, 'max_depth': 5}\n",
      "mean: -0.13468, std: 0.01119, params: {'min_samples_split': 4, 'loss': 'ls', 'n_estimators': 3957, 'max_depth': 5}\n",
      "mean: -0.13177, std: 0.01023, params: {'min_samples_split': 19, 'loss': 'ls', 'n_estimators': 506, 'max_depth': 4}\n",
      "mean: -0.13141, std: 0.01264, params: {'min_samples_split': 8, 'loss': 'ls', 'n_estimators': 2752, 'max_depth': 4}\n",
      "mean: -0.13150, std: 0.01041, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 1576, 'max_depth': 4}\n",
      "mean: -0.13313, std: 0.01233, params: {'min_samples_split': 6, 'loss': 'ls', 'n_estimators': 4487, 'max_depth': 4}\n",
      "mean: -0.13194, std: 0.01298, params: {'min_samples_split': 12, 'loss': 'ls', 'n_estimators': 1218, 'max_depth': 3}\n",
      "mean: -0.12882, std: 0.00834, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 4442, 'max_depth': 5}\n",
      "mean: -0.12614, std: 0.00834, params: {'min_samples_split': 7, 'loss': 'lad', 'n_estimators': 2299, 'max_depth': 4}\n",
      "mean: -0.13148, std: 0.01232, params: {'min_samples_split': 6, 'loss': 'ls', 'n_estimators': 3930, 'max_depth': 3}\n",
      "mean: -0.13180, std: 0.01118, params: {'min_samples_split': 17, 'loss': 'lad', 'n_estimators': 233, 'max_depth': 3}\n",
      "mean: -0.12759, std: 0.00951, params: {'min_samples_split': 5, 'loss': 'lad', 'n_estimators': 2740, 'max_depth': 4}\n",
      "mean: -0.13130, std: 0.00891, params: {'min_samples_split': 14, 'loss': 'lad', 'n_estimators': 4831, 'max_depth': 4}\n",
      "mean: -0.13107, std: 0.01373, params: {'min_samples_split': 19, 'loss': 'ls', 'n_estimators': 750, 'max_depth': 3}\n",
      "mean: -0.13521, std: 0.01211, params: {'min_samples_split': 12, 'loss': 'ls', 'n_estimators': 3922, 'max_depth': 5}\n",
      "mean: -0.13212, std: 0.01026, params: {'min_samples_split': 10, 'loss': 'ls', 'n_estimators': 1657, 'max_depth': 4}\n",
      "mean: -0.13264, std: 0.01272, params: {'min_samples_split': 11, 'loss': 'ls', 'n_estimators': 1895, 'max_depth': 3}\n",
      "mean: -0.13181, std: 0.01240, params: {'min_samples_split': 7, 'loss': 'ls', 'n_estimators': 1971, 'max_depth': 3}\n",
      "mean: -0.13536, std: 0.00889, params: {'min_samples_split': 14, 'loss': 'lad', 'n_estimators': 198, 'max_depth': 4}\n",
      "mean: -0.12621, std: 0.01212, params: {'min_samples_split': 19, 'loss': 'lad', 'n_estimators': 1614, 'max_depth': 5}\n",
      "mean: -0.12881, std: 0.00839, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 2882, 'max_depth': 5}\n",
      "mean: -0.12989, std: 0.01102, params: {'min_samples_split': 11, 'loss': 'lad', 'n_estimators': 4758, 'max_depth': 5}\n",
      "mean: -0.13515, std: 0.01231, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 4656, 'max_depth': 5}\n",
      "mean: -0.13074, std: 0.01111, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 3106, 'max_depth': 4}\n",
      "mean: -0.12930, std: 0.00900, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 1311, 'max_depth': 5}\n",
      "mean: -0.13057, std: 0.01199, params: {'min_samples_split': 15, 'loss': 'ls', 'n_estimators': 395, 'max_depth': 3}\n",
      "mean: -0.13235, std: 0.01102, params: {'min_samples_split': 15, 'loss': 'ls', 'n_estimators': 2953, 'max_depth': 3}\n",
      "mean: -0.12928, std: 0.01241, params: {'min_samples_split': 10, 'loss': 'lad', 'n_estimators': 1752, 'max_depth': 3}\n",
      "mean: -0.13427, std: 0.01351, params: {'min_samples_split': 14, 'loss': 'ls', 'n_estimators': 3274, 'max_depth': 5}\n",
      "mean: -0.13359, std: 0.01161, params: {'min_samples_split': 2, 'loss': 'ls', 'n_estimators': 3358, 'max_depth': 5}\n",
      "mean: -0.12839, std: 0.01211, params: {'min_samples_split': 8, 'loss': 'lad', 'n_estimators': 3458, 'max_depth': 3}\n",
      "mean: -0.13775, std: 0.00931, params: {'min_samples_split': 15, 'loss': 'ls', 'n_estimators': 62, 'max_depth': 4}\n",
      "mean: -0.12892, std: 0.01246, params: {'min_samples_split': 4, 'loss': 'lad', 'n_estimators': 298, 'max_depth': 4}\n",
      "mean: -0.12811, std: 0.01092, params: {'min_samples_split': 13, 'loss': 'lad', 'n_estimators': 3920, 'max_depth': 4}\n",
      "mean: -0.13560, std: 0.01231, params: {'min_samples_split': 11, 'loss': 'ls', 'n_estimators': 965, 'max_depth': 5}\n",
      "mean: -0.13158, std: 0.01120, params: {'min_samples_split': 4, 'loss': 'ls', 'n_estimators': 2812, 'max_depth': 3}\n",
      "mean: -0.13149, std: 0.01043, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 2561, 'max_depth': 4}\n",
      "mean: -0.12862, std: 0.00950, params: {'min_samples_split': 9, 'loss': 'lad', 'n_estimators': 1811, 'max_depth': 5}\n",
      "mean: -0.12816, std: 0.00839, params: {'min_samples_split': 10, 'loss': 'lad', 'n_estimators': 1288, 'max_depth': 4}\n",
      "mean: -0.12954, std: 0.01026, params: {'min_samples_split': 15, 'loss': 'lad', 'n_estimators': 1700, 'max_depth': 3}\n",
      "mean: -0.12869, std: 0.01013, params: {'min_samples_split': 15, 'loss': 'lad', 'n_estimators': 1350, 'max_depth': 4}\n",
      "mean: -0.13598, std: 0.01160, params: {'min_samples_split': 3, 'loss': 'ls', 'n_estimators': 1834, 'max_depth': 5}\n",
      "mean: -0.12806, std: 0.00927, params: {'min_samples_split': 17, 'loss': 'lad', 'n_estimators': 4178, 'max_depth': 5}\n",
      "mean: -0.12951, std: 0.00872, params: {'min_samples_split': 10, 'loss': 'lad', 'n_estimators': 325, 'max_depth': 4}\n",
      "mean: -0.13324, std: 0.01225, params: {'min_samples_split': 3, 'loss': 'ls', 'n_estimators': 894, 'max_depth': 4}\n",
      "mean: -0.12942, std: 0.01322, params: {'min_samples_split': 9, 'loss': 'ls', 'n_estimators': 4281, 'max_depth': 3}\n",
      "mean: -0.12591, std: 0.01153, params: {'min_samples_split': 19, 'loss': 'lad', 'n_estimators': 3190, 'max_depth': 5}\n",
      "mean: -0.13044, std: 0.01215, params: {'min_samples_split': 2, 'loss': 'ls', 'n_estimators': 569, 'max_depth': 4}\n",
      "mean: -0.12884, std: 0.01027, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 814, 'max_depth': 3}\n",
      "mean: -0.13249, std: 0.01061, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 4766, 'max_depth': 3}\n",
      "mean: -0.13210, std: 0.01031, params: {'min_samples_split': 10, 'loss': 'ls', 'n_estimators': 3353, 'max_depth': 4}\n",
      "mean: -0.12765, std: 0.00943, params: {'min_samples_split': 5, 'loss': 'lad', 'n_estimators': 3163, 'max_depth': 4}\n",
      "mean: -0.13417, std: 0.01180, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 1944, 'max_depth': 5}\n",
      "mean: -0.13112, std: 0.01206, params: {'min_samples_split': 12, 'loss': 'ls', 'n_estimators': 475, 'max_depth': 4}\n",
      "mean: -0.12844, std: 0.00950, params: {'min_samples_split': 16, 'loss': 'lad', 'n_estimators': 4194, 'max_depth': 4}\n",
      "mean: -0.13247, std: 0.00897, params: {'min_samples_split': 14, 'loss': 'lad', 'n_estimators': 566, 'max_depth': 4}\n",
      "mean: -0.13043, std: 0.01006, params: {'min_samples_split': 4, 'loss': 'lad', 'n_estimators': 2714, 'max_depth': 5}\n",
      "mean: -0.13172, std: 0.01317, params: {'min_samples_split': 10, 'loss': 'ls', 'n_estimators': 3322, 'max_depth': 3}\n",
      "mean: -0.12762, std: 0.00788, params: {'min_samples_split': 3, 'loss': 'lad', 'n_estimators': 2266, 'max_depth': 4}\n",
      "mean: -0.12916, std: 0.01004, params: {'min_samples_split': 9, 'loss': 'lad', 'n_estimators': 2899, 'max_depth': 4}\n",
      "mean: -0.12920, std: 0.01008, params: {'min_samples_split': 9, 'loss': 'lad', 'n_estimators': 3337, 'max_depth': 4}\n",
      "mean: -0.12628, std: 0.00837, params: {'min_samples_split': 7, 'loss': 'lad', 'n_estimators': 1854, 'max_depth': 4}\n",
      "mean: -0.13114, std: 0.01278, params: {'min_samples_split': 3, 'loss': 'ls', 'n_estimators': 1939, 'max_depth': 3}\n",
      " \n",
      "Best valid score (RMSLE):  0.125914888876\n",
      "Full data training score:  0.0515233036239\n",
      "{'min_samples_split': 19, 'loss': 'lad', 'n_estimators': 3190, 'max_depth': 5}\n",
      "\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 70.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 80.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.13323, std: 0.00944, params: {'min_samples_split': 15, 'loss': 'ls', 'n_estimators': 2000, 'max_depth': 5}\n",
      "mean: -0.13412, std: 0.01001, params: {'min_samples_split': 11, 'loss': 'ls', 'n_estimators': 2512, 'max_depth': 5}\n",
      "mean: -0.12837, std: 0.01303, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 2835, 'max_depth': 4}\n",
      "mean: -0.12345, std: 0.01050, params: {'min_samples_split': 16, 'loss': 'lad', 'n_estimators': 4634, 'max_depth': 3}\n",
      "mean: -0.12725, std: 0.01099, params: {'min_samples_split': 14, 'loss': 'lad', 'n_estimators': 4097, 'max_depth': 4}\n",
      "mean: -0.12396, std: 0.01200, params: {'min_samples_split': 13, 'loss': 'lad', 'n_estimators': 4170, 'max_depth': 4}\n",
      "mean: -0.12708, std: 0.01301, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 726, 'max_depth': 3}\n",
      "mean: -0.13183, std: 0.01246, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 2006, 'max_depth': 5}\n",
      "mean: -0.12758, std: 0.01298, params: {'min_samples_split': 12, 'loss': 'ls', 'n_estimators': 4819, 'max_depth': 4}\n",
      "mean: -0.13466, std: 0.01344, params: {'min_samples_split': 2, 'loss': 'ls', 'n_estimators': 192, 'max_depth': 5}\n",
      "mean: -0.13404, std: 0.01343, params: {'min_samples_split': 2, 'loss': 'ls', 'n_estimators': 2062, 'max_depth': 5}\n",
      "mean: -0.12598, std: 0.00858, params: {'min_samples_split': 4, 'loss': 'lad', 'n_estimators': 897, 'max_depth': 5}\n",
      "mean: -0.13387, std: 0.01133, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 107, 'max_depth': 5}\n",
      "mean: -0.12479, std: 0.01107, params: {'min_samples_split': 11, 'loss': 'lad', 'n_estimators': 1119, 'max_depth': 5}\n",
      "mean: -0.12719, std: 0.01244, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 2041, 'max_depth': 3}\n",
      "mean: -0.12679, std: 0.01270, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 1733, 'max_depth': 3}\n",
      "mean: -0.12810, std: 0.01251, params: {'min_samples_split': 5, 'loss': 'ls', 'n_estimators': 1207, 'max_depth': 4}\n",
      "mean: -0.12342, std: 0.01268, params: {'min_samples_split': 7, 'loss': 'lad', 'n_estimators': 2935, 'max_depth': 4}\n",
      "mean: -0.12790, std: 0.01202, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 195, 'max_depth': 3}\n",
      "mean: -0.12485, std: 0.01107, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 2526, 'max_depth': 5}\n",
      "mean: -0.12681, std: 0.01273, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 1884, 'max_depth': 3}\n",
      "mean: -0.12773, std: 0.01391, params: {'min_samples_split': 9, 'loss': 'ls', 'n_estimators': 3671, 'max_depth': 4}\n",
      "mean: -0.12360, std: 0.01146, params: {'min_samples_split': 4, 'loss': 'lad', 'n_estimators': 3092, 'max_depth': 3}\n",
      "mean: -0.12729, std: 0.01243, params: {'min_samples_split': 7, 'loss': 'ls', 'n_estimators': 1402, 'max_depth': 3}\n",
      "mean: -0.12378, std: 0.00886, params: {'min_samples_split': 19, 'loss': 'lad', 'n_estimators': 2108, 'max_depth': 4}\n",
      "mean: -0.12718, std: 0.01245, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 1957, 'max_depth': 3}\n",
      "mean: -0.12795, std: 0.01210, params: {'min_samples_split': 6, 'loss': 'ls', 'n_estimators': 594, 'max_depth': 4}\n",
      "mean: -0.12538, std: 0.01145, params: {'min_samples_split': 8, 'loss': 'lad', 'n_estimators': 4282, 'max_depth': 3}\n",
      "mean: -0.12563, std: 0.01018, params: {'min_samples_split': 10, 'loss': 'lad', 'n_estimators': 1066, 'max_depth': 5}\n",
      "mean: -0.12530, std: 0.01044, params: {'min_samples_split': 8, 'loss': 'lad', 'n_estimators': 4097, 'max_depth': 5}\n",
      "mean: -0.12411, std: 0.01084, params: {'min_samples_split': 11, 'loss': 'lad', 'n_estimators': 2060, 'max_depth': 4}\n",
      "mean: -0.13196, std: 0.01239, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 550, 'max_depth': 5}\n",
      "mean: -0.12712, std: 0.01217, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 4527, 'max_depth': 3}\n",
      "mean: -0.12986, std: 0.01362, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 3150, 'max_depth': 4}\n",
      "mean: -0.13246, std: 0.01137, params: {'min_samples_split': 18, 'loss': 'ls', 'n_estimators': 2467, 'max_depth': 5}\n",
      "mean: -0.12937, std: 0.01314, params: {'min_samples_split': 17, 'loss': 'ls', 'n_estimators': 1978, 'max_depth': 4}\n",
      "mean: -0.12735, std: 0.01261, params: {'min_samples_split': 11, 'loss': 'ls', 'n_estimators': 4047, 'max_depth': 3}\n",
      "mean: -0.12573, std: 0.01145, params: {'min_samples_split': 17, 'loss': 'lad', 'n_estimators': 3485, 'max_depth': 5}\n",
      "mean: -0.13615, std: 0.01146, params: {'min_samples_split': 4, 'loss': 'ls', 'n_estimators': 3957, 'max_depth': 5}\n",
      "mean: -0.12903, std: 0.01377, params: {'min_samples_split': 19, 'loss': 'ls', 'n_estimators': 506, 'max_depth': 4}\n",
      "mean: -0.12835, std: 0.01116, params: {'min_samples_split': 8, 'loss': 'ls', 'n_estimators': 2752, 'max_depth': 4}\n",
      "mean: -0.12905, std: 0.01308, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 1576, 'max_depth': 4}\n",
      "mean: -0.12784, std: 0.01225, params: {'min_samples_split': 6, 'loss': 'ls', 'n_estimators': 4487, 'max_depth': 4}\n",
      "mean: -0.12743, std: 0.01238, params: {'min_samples_split': 12, 'loss': 'ls', 'n_estimators': 1218, 'max_depth': 3}\n",
      "mean: -0.12476, std: 0.01126, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 4442, 'max_depth': 5}\n",
      "mean: -0.12352, std: 0.01268, params: {'min_samples_split': 7, 'loss': 'lad', 'n_estimators': 2299, 'max_depth': 4}\n",
      "mean: -0.12658, std: 0.01220, params: {'min_samples_split': 6, 'loss': 'ls', 'n_estimators': 3930, 'max_depth': 3}\n",
      "mean: -0.12851, std: 0.01052, params: {'min_samples_split': 17, 'loss': 'lad', 'n_estimators': 233, 'max_depth': 3}\n",
      "mean: -0.12412, std: 0.01079, params: {'min_samples_split': 5, 'loss': 'lad', 'n_estimators': 2740, 'max_depth': 4}\n",
      "mean: -0.12726, std: 0.01100, params: {'min_samples_split': 14, 'loss': 'lad', 'n_estimators': 4831, 'max_depth': 4}\n",
      "mean: -0.12656, std: 0.01192, params: {'min_samples_split': 19, 'loss': 'ls', 'n_estimators': 750, 'max_depth': 3}\n",
      "mean: -0.13373, std: 0.01003, params: {'min_samples_split': 12, 'loss': 'ls', 'n_estimators': 3922, 'max_depth': 5}\n",
      "mean: -0.12817, std: 0.01417, params: {'min_samples_split': 10, 'loss': 'ls', 'n_estimators': 1657, 'max_depth': 4}\n",
      "mean: -0.12727, std: 0.01253, params: {'min_samples_split': 11, 'loss': 'ls', 'n_estimators': 1895, 'max_depth': 3}\n",
      "mean: -0.12712, std: 0.01243, params: {'min_samples_split': 7, 'loss': 'ls', 'n_estimators': 1971, 'max_depth': 3}\n",
      "mean: -0.13120, std: 0.01115, params: {'min_samples_split': 14, 'loss': 'lad', 'n_estimators': 198, 'max_depth': 4}\n",
      "mean: -0.12532, std: 0.01141, params: {'min_samples_split': 19, 'loss': 'lad', 'n_estimators': 1614, 'max_depth': 5}\n",
      "mean: -0.12476, std: 0.01106, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 2882, 'max_depth': 5}\n",
      "mean: -0.12432, std: 0.01033, params: {'min_samples_split': 11, 'loss': 'lad', 'n_estimators': 4758, 'max_depth': 5}\n",
      "mean: -0.13263, std: 0.01274, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 4656, 'max_depth': 5}\n",
      "mean: -0.12837, std: 0.01303, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 3106, 'max_depth': 4}\n",
      "mean: -0.12546, std: 0.01111, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 1311, 'max_depth': 5}\n",
      "mean: -0.12731, std: 0.01178, params: {'min_samples_split': 15, 'loss': 'ls', 'n_estimators': 395, 'max_depth': 3}\n",
      "mean: -0.12751, std: 0.01144, params: {'min_samples_split': 15, 'loss': 'ls', 'n_estimators': 2953, 'max_depth': 3}\n",
      "mean: -0.12389, std: 0.01180, params: {'min_samples_split': 10, 'loss': 'lad', 'n_estimators': 1752, 'max_depth': 3}\n",
      "mean: -0.13346, std: 0.01098, params: {'min_samples_split': 14, 'loss': 'ls', 'n_estimators': 3274, 'max_depth': 5}\n",
      "mean: -0.13404, std: 0.01343, params: {'min_samples_split': 2, 'loss': 'ls', 'n_estimators': 3358, 'max_depth': 5}\n",
      "mean: -0.12543, std: 0.01157, params: {'min_samples_split': 8, 'loss': 'lad', 'n_estimators': 3458, 'max_depth': 3}\n",
      "mean: -0.13311, std: 0.01251, params: {'min_samples_split': 15, 'loss': 'ls', 'n_estimators': 62, 'max_depth': 4}\n",
      "mean: -0.12786, std: 0.01336, params: {'min_samples_split': 4, 'loss': 'lad', 'n_estimators': 298, 'max_depth': 4}\n",
      "mean: -0.12395, std: 0.01197, params: {'min_samples_split': 13, 'loss': 'lad', 'n_estimators': 3920, 'max_depth': 4}\n",
      "mean: -0.13416, std: 0.00998, params: {'min_samples_split': 11, 'loss': 'ls', 'n_estimators': 965, 'max_depth': 5}\n",
      "mean: -0.12446, std: 0.01303, params: {'min_samples_split': 4, 'loss': 'ls', 'n_estimators': 2812, 'max_depth': 3}\n",
      "mean: -0.12904, std: 0.01307, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 2561, 'max_depth': 4}\n",
      "mean: -0.12618, std: 0.00987, params: {'min_samples_split': 9, 'loss': 'lad', 'n_estimators': 1811, 'max_depth': 5}\n",
      "mean: -0.12443, std: 0.01114, params: {'min_samples_split': 10, 'loss': 'lad', 'n_estimators': 1288, 'max_depth': 4}\n",
      "mean: -0.12536, std: 0.01033, params: {'min_samples_split': 15, 'loss': 'lad', 'n_estimators': 1700, 'max_depth': 3}\n",
      "mean: -0.12450, std: 0.01075, params: {'min_samples_split': 15, 'loss': 'lad', 'n_estimators': 1350, 'max_depth': 4}\n",
      "mean: -0.13414, std: 0.01260, params: {'min_samples_split': 3, 'loss': 'ls', 'n_estimators': 1834, 'max_depth': 5}\n",
      "mean: -0.12575, std: 0.01142, params: {'min_samples_split': 17, 'loss': 'lad', 'n_estimators': 4178, 'max_depth': 5}\n",
      "mean: -0.12681, std: 0.01115, params: {'min_samples_split': 10, 'loss': 'lad', 'n_estimators': 325, 'max_depth': 4}\n",
      "mean: -0.12734, std: 0.01183, params: {'min_samples_split': 3, 'loss': 'ls', 'n_estimators': 894, 'max_depth': 4}\n",
      "mean: -0.12806, std: 0.01183, params: {'min_samples_split': 9, 'loss': 'ls', 'n_estimators': 4281, 'max_depth': 3}\n",
      "mean: -0.12466, std: 0.01129, params: {'min_samples_split': 19, 'loss': 'lad', 'n_estimators': 3190, 'max_depth': 5}\n",
      "mean: -0.12746, std: 0.01244, params: {'min_samples_split': 2, 'loss': 'ls', 'n_estimators': 569, 'max_depth': 4}\n",
      "mean: -0.12427, std: 0.01182, params: {'min_samples_split': 12, 'loss': 'lad', 'n_estimators': 814, 'max_depth': 3}\n",
      "mean: -0.12711, std: 0.01218, params: {'min_samples_split': 16, 'loss': 'ls', 'n_estimators': 4766, 'max_depth': 3}\n",
      "mean: -0.12814, std: 0.01419, params: {'min_samples_split': 10, 'loss': 'ls', 'n_estimators': 3353, 'max_depth': 4}\n",
      "mean: -0.12418, std: 0.01072, params: {'min_samples_split': 5, 'loss': 'lad', 'n_estimators': 3163, 'max_depth': 4}\n",
      "mean: -0.13303, std: 0.01075, params: {'min_samples_split': 13, 'loss': 'ls', 'n_estimators': 1944, 'max_depth': 5}\n",
      "mean: -0.12778, std: 0.01303, params: {'min_samples_split': 12, 'loss': 'ls', 'n_estimators': 475, 'max_depth': 4}\n",
      "mean: -0.12347, std: 0.01020, params: {'min_samples_split': 16, 'loss': 'lad', 'n_estimators': 4194, 'max_depth': 4}\n",
      "mean: -0.12813, std: 0.01084, params: {'min_samples_split': 14, 'loss': 'lad', 'n_estimators': 566, 'max_depth': 4}\n",
      "mean: -0.12538, std: 0.00854, params: {'min_samples_split': 4, 'loss': 'lad', 'n_estimators': 2714, 'max_depth': 5}\n",
      "mean: -0.12773, std: 0.01154, params: {'min_samples_split': 10, 'loss': 'ls', 'n_estimators': 3322, 'max_depth': 3}\n",
      "mean: -0.12584, std: 0.01079, params: {'min_samples_split': 3, 'loss': 'lad', 'n_estimators': 2266, 'max_depth': 4}\n",
      "mean: -0.12557, std: 0.01085, params: {'min_samples_split': 9, 'loss': 'lad', 'n_estimators': 2899, 'max_depth': 4}\n",
      "mean: -0.12546, std: 0.01097, params: {'min_samples_split': 9, 'loss': 'lad', 'n_estimators': 3337, 'max_depth': 4}\n",
      "mean: -0.12362, std: 0.01277, params: {'min_samples_split': 7, 'loss': 'lad', 'n_estimators': 1854, 'max_depth': 4}\n",
      "mean: -0.12567, std: 0.01179, params: {'min_samples_split': 3, 'loss': 'ls', 'n_estimators': 1939, 'max_depth': 3}\n",
      " \n",
      "Best valid score (RMSLE):  0.123418467609\n",
      "Full data training score:  0.0600415806453\n",
      "{'min_samples_split': 7, 'loss': 'lad', 'n_estimators': 2935, 'max_depth': 4}\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbr_def = GradientBoostingRegressor(random_state=666)\n",
    "params = {'min_samples_split': scipy.stats.randint(low=2, high=20), 'n_estimators': scipy.stats.randint(low=50, high=5000), 'max_depth': [3, 4, 5], 'loss': ['ls', 'lad']}\n",
    "np.random.seed(666)\n",
    "gbr_model = my.make_model(features, prices, gbr_def, params, cv=kf, grid_type='random', n_iter=100, n_jobs=-1)\n",
    "np.random.seed(666)\n",
    "gbr_log_model = my.make_model(features, logSalePrice, gbr_def, params, cv=kf, y_type='log1p', grid_type='random', n_iter=100, n_jobs=-1)\n",
    "\n",
    "scores = pd.DataFrame([['GBR', str(gbr_model.best_params_), -gbr_model.best_score_]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores = model_scores.append(scores)\n",
    "scores = pd.DataFrame([['GBR', str(gbr_log_model.best_params_), -gbr_log_model.best_score_]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores_log = model_scores_log.append(scores)\n",
    "\n",
    "my.fit_submit(test_features, test_id, gbr_model, '../data/submissions/gbr.csv')\n",
    "my.fit_submit(test_features, test_id, gbr_log_model, '../data/submissions/gbr_log.csv', price_type='log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating/finding a Random Forest model, both for original SalesPrice and for the log-transformed variable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 90.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 223.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 255.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.14398, std: 0.00907, params: {'min_samples_split': 4, 'n_estimators': 2000, 'bootstrap': True}\n",
      "mean: -0.14454, std: 0.00876, params: {'min_samples_split': 8, 'n_estimators': 2043, 'bootstrap': True}\n",
      "mean: -0.14433, std: 0.00899, params: {'min_samples_split': 6, 'n_estimators': 1519, 'bootstrap': True}\n",
      "mean: -0.19933, std: 0.00789, params: {'min_samples_split': 16, 'n_estimators': 2835, 'bootstrap': False}\n",
      "mean: -0.19755, std: 0.00778, params: {'min_samples_split': 18, 'n_estimators': 3168, 'bootstrap': False}\n",
      "mean: -0.14480, std: 0.00890, params: {'min_samples_split': 9, 'n_estimators': 3191, 'bootstrap': True}\n",
      "mean: -0.14671, std: 0.00832, params: {'min_samples_split': 14, 'n_estimators': 4097, 'bootstrap': True}\n",
      "mean: -0.20091, std: 0.00892, params: {'min_samples_split': 7, 'n_estimators': 935, 'bootstrap': False}\n",
      "mean: -0.14630, std: 0.00846, params: {'min_samples_split': 13, 'n_estimators': 4170, 'bootstrap': True}\n",
      "mean: -0.14414, std: 0.00886, params: {'min_samples_split': 6, 'n_estimators': 674, 'bootstrap': True}\n",
      "mean: -0.14429, std: 0.00913, params: {'min_samples_split': 6, 'n_estimators': 3984, 'bootstrap': True}\n",
      "mean: -0.14772, std: 0.00801, params: {'min_samples_split': 17, 'n_estimators': 2006, 'bootstrap': True}\n",
      "mean: -0.14449, std: 0.00880, params: {'min_samples_split': 7, 'n_estimators': 604, 'bootstrap': True}\n",
      "mean: -0.19954, std: 0.00730, params: {'min_samples_split': 15, 'n_estimators': 4819, 'bootstrap': False}\n",
      "mean: -0.14485, std: 0.00898, params: {'min_samples_split': 2, 'n_estimators': 192, 'bootstrap': True}\n",
      "mean: -0.14469, std: 0.00892, params: {'min_samples_split': 8, 'n_estimators': 3826, 'bootstrap': True}\n",
      "mean: -0.14415, std: 0.00909, params: {'min_samples_split': 4, 'n_estimators': 4651, 'bootstrap': True}\n",
      "mean: -0.20205, std: 0.00871, params: {'min_samples_split': 4, 'n_estimators': 897, 'bootstrap': False}\n",
      "mean: -0.14455, std: 0.00883, params: {'min_samples_split': 8, 'n_estimators': 2253, 'bootstrap': True}\n",
      "mean: -0.14459, std: 0.00891, params: {'min_samples_split': 8, 'n_estimators': 3131, 'bootstrap': True}\n",
      "mean: -0.19966, std: 0.00729, params: {'min_samples_split': 15, 'n_estimators': 1119, 'bootstrap': False}\n",
      "mean: -0.14432, std: 0.00900, params: {'min_samples_split': 6, 'n_estimators': 1585, 'bootstrap': True}\n",
      "mean: -0.14611, std: 0.00830, params: {'min_samples_split': 13, 'n_estimators': 2041, 'bootstrap': True}\n",
      "mean: -0.14779, std: 0.00799, params: {'min_samples_split': 17, 'n_estimators': 1733, 'bootstrap': True}\n",
      "mean: -0.14783, std: 0.00815, params: {'min_samples_split': 17, 'n_estimators': 3377, 'bootstrap': True}\n",
      "mean: -0.20208, std: 0.00898, params: {'min_samples_split': 5, 'n_estimators': 1207, 'bootstrap': False}\n",
      "mean: -0.20101, std: 0.00897, params: {'min_samples_split': 7, 'n_estimators': 2935, 'bootstrap': False}\n",
      "mean: -0.14865, std: 0.00786, params: {'min_samples_split': 18, 'n_estimators': 195, 'bootstrap': True}\n",
      "mean: -0.19915, std: 0.00807, params: {'min_samples_split': 12, 'n_estimators': 2526, 'bootstrap': False}\n",
      "mean: -0.14779, std: 0.00795, params: {'min_samples_split': 17, 'n_estimators': 1884, 'bootstrap': True}\n",
      "mean: -0.14413, std: 0.00906, params: {'min_samples_split': 3, 'n_estimators': 4441, 'bootstrap': True}\n",
      "mean: -0.19958, std: 0.00726, params: {'min_samples_split': 14, 'n_estimators': 3972, 'bootstrap': False}\n",
      "mean: -0.14398, std: 0.00892, params: {'min_samples_split': 4, 'n_estimators': 718, 'bootstrap': True}\n",
      "mean: -0.14438, std: 0.00889, params: {'min_samples_split': 7, 'n_estimators': 1402, 'bootstrap': True}\n",
      "mean: -0.20100, std: 0.00897, params: {'min_samples_split': 7, 'n_estimators': 2723, 'bootstrap': False}\n",
      "mean: -0.14510, std: 0.00869, params: {'min_samples_split': 10, 'n_estimators': 1957, 'bootstrap': True}\n",
      "mean: -0.14424, std: 0.00877, params: {'min_samples_split': 6, 'n_estimators': 594, 'bootstrap': True}\n",
      "mean: -0.20135, std: 0.00952, params: {'min_samples_split': 6, 'n_estimators': 4282, 'bootstrap': False}\n",
      "mean: -0.20192, std: 0.00864, params: {'min_samples_split': 4, 'n_estimators': 3898, 'bootstrap': False}\n",
      "mean: -0.20199, std: 0.00866, params: {'min_samples_split': 2, 'n_estimators': 1066, 'bootstrap': False}\n",
      "mean: -0.20002, std: 0.00862, params: {'min_samples_split': 8, 'n_estimators': 4097, 'bootstrap': False}\n",
      "mean: -0.20099, std: 0.00894, params: {'min_samples_split': 7, 'n_estimators': 2060, 'bootstrap': False}\n",
      "mean: -0.14471, std: 0.00836, params: {'min_samples_split': 9, 'n_estimators': 513, 'bootstrap': True}\n",
      "mean: -0.14820, std: 0.00809, params: {'min_samples_split': 18, 'n_estimators': 2432, 'bootstrap': True}\n",
      "mean: -0.19720, std: 0.00762, params: {'min_samples_split': 19, 'n_estimators': 2178, 'bootstrap': False}\n",
      "mean: -0.14589, std: 0.00858, params: {'min_samples_split': 12, 'n_estimators': 4660, 'bootstrap': True}\n",
      "mean: -0.14872, std: 0.00774, params: {'min_samples_split': 19, 'n_estimators': 592, 'bootstrap': True}\n",
      "mean: -0.19856, std: 0.00729, params: {'min_samples_split': 17, 'n_estimators': 1978, 'bootstrap': False}\n",
      "mean: -0.14819, std: 0.00808, params: {'min_samples_split': 18, 'n_estimators': 2459, 'bootstrap': True}\n",
      "mean: -0.14621, std: 0.00835, params: {'min_samples_split': 13, 'n_estimators': 2544, 'bootstrap': True}\n",
      "mean: -0.19876, std: 0.00803, params: {'min_samples_split': 11, 'n_estimators': 3485, 'bootstrap': False}\n",
      "mean: -0.14413, std: 0.00913, params: {'min_samples_split': 4, 'n_estimators': 3957, 'bootstrap': True}\n",
      "mean: -0.14553, std: 0.00866, params: {'min_samples_split': 11, 'n_estimators': 3011, 'bootstrap': True}\n",
      "mean: -0.19911, std: 0.00755, params: {'min_samples_split': 10, 'n_estimators': 216, 'bootstrap': False}\n",
      "mean: -0.14470, std: 0.00890, params: {'min_samples_split': 8, 'n_estimators': 4251, 'bootstrap': True}\n",
      "mean: -0.19863, std: 0.00704, params: {'min_samples_split': 13, 'n_estimators': 1576, 'bootstrap': False}\n",
      "mean: -0.14540, std: 0.00862, params: {'min_samples_split': 11, 'n_estimators': 1046, 'bootstrap': True}\n",
      "mean: -0.19975, std: 0.00729, params: {'min_samples_split': 14, 'n_estimators': 578, 'bootstrap': False}\n",
      "mean: -0.19901, std: 0.00809, params: {'min_samples_split': 12, 'n_estimators': 1218, 'bootstrap': False}\n",
      "mean: -0.19917, std: 0.00809, params: {'min_samples_split': 12, 'n_estimators': 4442, 'bootstrap': False}\n",
      "mean: -0.20097, std: 0.00895, params: {'min_samples_split': 7, 'n_estimators': 2299, 'bootstrap': False}\n",
      "mean: -0.14430, std: 0.00913, params: {'min_samples_split': 6, 'n_estimators': 3930, 'bootstrap': True}\n",
      "mean: -0.20141, std: 0.00957, params: {'min_samples_split': 6, 'n_estimators': 1481, 'bootstrap': False}\n",
      "mean: -0.19878, std: 0.00804, params: {'min_samples_split': 11, 'n_estimators': 2289, 'bootstrap': False}\n",
      "mean: -0.20202, std: 0.00895, params: {'min_samples_split': 5, 'n_estimators': 2740, 'bootstrap': False}\n",
      "mean: -0.19957, std: 0.00725, params: {'min_samples_split': 14, 'n_estimators': 4831, 'bootstrap': False}\n",
      "mean: -0.14427, std: 0.00907, params: {'min_samples_split': 6, 'n_estimators': 4624, 'bootstrap': True}\n",
      "mean: -0.20214, std: 0.00899, params: {'min_samples_split': 5, 'n_estimators': 693, 'bootstrap': False}\n",
      "mean: -0.19858, std: 0.00730, params: {'min_samples_split': 17, 'n_estimators': 2161, 'bootstrap': False}\n",
      "mean: -0.19920, std: 0.00809, params: {'min_samples_split': 12, 'n_estimators': 3922, 'bootstrap': False}\n",
      "mean: -0.14556, std: 0.00868, params: {'min_samples_split': 11, 'n_estimators': 4634, 'bootstrap': True}\n",
      "mean: -0.14478, std: 0.00874, params: {'min_samples_split': 9, 'n_estimators': 1966, 'bootstrap': True}\n",
      "mean: -0.19932, std: 0.00789, params: {'min_samples_split': 16, 'n_estimators': 3262, 'bootstrap': False}\n",
      "mean: -0.20099, std: 0.00897, params: {'min_samples_split': 7, 'n_estimators': 1971, 'bootstrap': False}\n",
      "mean: -0.19961, std: 0.00730, params: {'min_samples_split': 15, 'n_estimators': 2078, 'bootstrap': False}\n",
      "mean: -0.14871, std: 0.00806, params: {'min_samples_split': 19, 'n_estimators': 2977, 'bootstrap': True}\n",
      "mean: -0.14869, std: 0.00798, params: {'min_samples_split': 19, 'n_estimators': 1614, 'bootstrap': True}\n",
      "mean: -0.19929, std: 0.00789, params: {'min_samples_split': 16, 'n_estimators': 3836, 'bootstrap': False}\n",
      "mean: -0.14828, std: 0.00813, params: {'min_samples_split': 18, 'n_estimators': 4783, 'bootstrap': True}\n",
      "mean: -0.14556, std: 0.00866, params: {'min_samples_split': 11, 'n_estimators': 4758, 'bootstrap': True}\n",
      "mean: -0.14420, std: 0.00914, params: {'min_samples_split': 5, 'n_estimators': 3617, 'bootstrap': True}\n",
      "mean: -0.14746, std: 0.00823, params: {'min_samples_split': 16, 'n_estimators': 4656, 'bootstrap': True}\n",
      "mean: -0.14740, std: 0.00823, params: {'min_samples_split': 16, 'n_estimators': 3106, 'bootstrap': True}\n",
      "mean: -0.20194, std: 0.00864, params: {'min_samples_split': 4, 'n_estimators': 3470, 'bootstrap': False}\n",
      "mean: -0.14445, std: 0.00897, params: {'min_samples_split': 7, 'n_estimators': 1311, 'bootstrap': True}\n",
      "mean: -0.14696, std: 0.00793, params: {'min_samples_split': 15, 'n_estimators': 395, 'bootstrap': True}\n",
      "mean: -0.14523, std: 0.00882, params: {'min_samples_split': 10, 'n_estimators': 4511, 'bootstrap': True}\n",
      "mean: -0.19894, std: 0.00775, params: {'min_samples_split': 10, 'n_estimators': 1752, 'bootstrap': False}\n",
      "mean: -0.14468, std: 0.00888, params: {'min_samples_split': 8, 'n_estimators': 4798, 'bootstrap': True}\n",
      "mean: -0.14400, std: 0.00911, params: {'min_samples_split': 2, 'n_estimators': 2200, 'bootstrap': True}\n",
      "mean: -0.14481, std: 0.00887, params: {'min_samples_split': 9, 'n_estimators': 3358, 'bootstrap': True}\n",
      "mean: -0.20004, std: 0.00861, params: {'min_samples_split': 8, 'n_estimators': 3458, 'bootstrap': False}\n",
      "mean: -0.14836, std: 0.00856, params: {'min_samples_split': 15, 'n_estimators': 62, 'bootstrap': True}\n",
      "mean: -0.20207, std: 0.00863, params: {'min_samples_split': 3, 'n_estimators': 4468, 'bootstrap': False}\n",
      "mean: -0.20182, std: 0.00847, params: {'min_samples_split': 3, 'n_estimators': 298, 'bootstrap': False}\n",
      "mean: -0.19857, std: 0.00703, params: {'min_samples_split': 13, 'n_estimators': 3179, 'bootstrap': False}\n",
      "mean: -0.19892, std: 0.00771, params: {'min_samples_split': 10, 'n_estimators': 4365, 'bootstrap': False}\n",
      "mean: -0.14542, std: 0.00865, params: {'min_samples_split': 11, 'n_estimators': 965, 'bootstrap': True}\n",
      "mean: -0.14405, std: 0.00915, params: {'min_samples_split': 4, 'n_estimators': 2812, 'bootstrap': True}\n",
      "mean: -0.14445, std: 0.00892, params: {'min_samples_split': 7, 'n_estimators': 2561, 'bootstrap': True}\n",
      " \n",
      "Best valid score (RMSLE):  0.14398054494\n",
      "Full data training score:  0.0631653099866\n",
      "{'min_samples_split': 4, 'n_estimators': 718, 'bootstrap': True}\n",
      "\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 86.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 215.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 247.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.14220, std: 0.01006, params: {'min_samples_split': 4, 'n_estimators': 2000, 'bootstrap': True}\n",
      "mean: -0.14281, std: 0.00990, params: {'min_samples_split': 8, 'n_estimators': 2043, 'bootstrap': True}\n",
      "mean: -0.14230, std: 0.01001, params: {'min_samples_split': 6, 'n_estimators': 1519, 'bootstrap': True}\n",
      "mean: -0.18883, std: 0.00994, params: {'min_samples_split': 16, 'n_estimators': 2835, 'bootstrap': False}\n",
      "mean: -0.18803, std: 0.01003, params: {'min_samples_split': 18, 'n_estimators': 3168, 'bootstrap': False}\n",
      "mean: -0.14282, std: 0.01004, params: {'min_samples_split': 9, 'n_estimators': 3191, 'bootstrap': True}\n",
      "mean: -0.14408, std: 0.00965, params: {'min_samples_split': 14, 'n_estimators': 4097, 'bootstrap': True}\n",
      "mean: -0.19177, std: 0.01176, params: {'min_samples_split': 7, 'n_estimators': 935, 'bootstrap': False}\n",
      "mean: -0.14381, std: 0.00970, params: {'min_samples_split': 13, 'n_estimators': 4170, 'bootstrap': True}\n",
      "mean: -0.14218, std: 0.00981, params: {'min_samples_split': 6, 'n_estimators': 674, 'bootstrap': True}\n",
      "mean: -0.14224, std: 0.01027, params: {'min_samples_split': 6, 'n_estimators': 3984, 'bootstrap': True}\n",
      "mean: -0.14526, std: 0.00924, params: {'min_samples_split': 17, 'n_estimators': 2006, 'bootstrap': True}\n",
      "mean: -0.14248, std: 0.00957, params: {'min_samples_split': 7, 'n_estimators': 604, 'bootstrap': True}\n",
      "mean: -0.18927, std: 0.01054, params: {'min_samples_split': 15, 'n_estimators': 4819, 'bootstrap': False}\n",
      "mean: -0.14230, std: 0.00946, params: {'min_samples_split': 2, 'n_estimators': 192, 'bootstrap': True}\n",
      "mean: -0.14260, std: 0.01014, params: {'min_samples_split': 8, 'n_estimators': 3826, 'bootstrap': True}\n",
      "mean: -0.14207, std: 0.01034, params: {'min_samples_split': 4, 'n_estimators': 4651, 'bootstrap': True}\n",
      "mean: -0.19175, std: 0.01135, params: {'min_samples_split': 4, 'n_estimators': 897, 'bootstrap': False}\n",
      "mean: -0.14281, std: 0.00997, params: {'min_samples_split': 8, 'n_estimators': 2253, 'bootstrap': True}\n",
      "mean: -0.14266, std: 0.01014, params: {'min_samples_split': 8, 'n_estimators': 3131, 'bootstrap': True}\n",
      "mean: -0.18932, std: 0.01059, params: {'min_samples_split': 15, 'n_estimators': 1119, 'bootstrap': False}\n",
      "mean: -0.14230, std: 0.01001, params: {'min_samples_split': 6, 'n_estimators': 1585, 'bootstrap': True}\n",
      "mean: -0.14397, std: 0.00949, params: {'min_samples_split': 13, 'n_estimators': 2041, 'bootstrap': True}\n",
      "mean: -0.14527, std: 0.00922, params: {'min_samples_split': 17, 'n_estimators': 1733, 'bootstrap': True}\n",
      "mean: -0.14507, std: 0.00952, params: {'min_samples_split': 17, 'n_estimators': 3377, 'bootstrap': True}\n",
      "mean: -0.19184, std: 0.01105, params: {'min_samples_split': 5, 'n_estimators': 1207, 'bootstrap': False}\n",
      "mean: -0.19179, std: 0.01167, params: {'min_samples_split': 7, 'n_estimators': 2935, 'bootstrap': False}\n",
      "mean: -0.14557, std: 0.00871, params: {'min_samples_split': 18, 'n_estimators': 195, 'bootstrap': True}\n",
      "mean: -0.19095, std: 0.01149, params: {'min_samples_split': 12, 'n_estimators': 2526, 'bootstrap': False}\n",
      "mean: -0.14528, std: 0.00923, params: {'min_samples_split': 17, 'n_estimators': 1884, 'bootstrap': True}\n",
      "mean: -0.14212, std: 0.01032, params: {'min_samples_split': 3, 'n_estimators': 4441, 'bootstrap': True}\n",
      "mean: -0.19034, std: 0.01089, params: {'min_samples_split': 14, 'n_estimators': 3972, 'bootstrap': False}\n",
      "mean: -0.14212, std: 0.00973, params: {'min_samples_split': 4, 'n_estimators': 718, 'bootstrap': True}\n",
      "mean: -0.14251, std: 0.00984, params: {'min_samples_split': 7, 'n_estimators': 1402, 'bootstrap': True}\n",
      "mean: -0.19177, std: 0.01168, params: {'min_samples_split': 7, 'n_estimators': 2723, 'bootstrap': False}\n",
      "mean: -0.14320, std: 0.00974, params: {'min_samples_split': 10, 'n_estimators': 1957, 'bootstrap': True}\n",
      "mean: -0.14219, std: 0.00981, params: {'min_samples_split': 6, 'n_estimators': 594, 'bootstrap': True}\n",
      "mean: -0.19136, std: 0.01161, params: {'min_samples_split': 6, 'n_estimators': 4282, 'bootstrap': False}\n",
      "mean: -0.19178, std: 0.01133, params: {'min_samples_split': 4, 'n_estimators': 3898, 'bootstrap': False}\n",
      "mean: -0.19174, std: 0.01122, params: {'min_samples_split': 2, 'n_estimators': 1066, 'bootstrap': False}\n",
      "mean: -0.19262, std: 0.01187, params: {'min_samples_split': 8, 'n_estimators': 4097, 'bootstrap': False}\n",
      "mean: -0.19174, std: 0.01175, params: {'min_samples_split': 7, 'n_estimators': 2060, 'bootstrap': False}\n",
      "mean: -0.14268, std: 0.00949, params: {'min_samples_split': 9, 'n_estimators': 513, 'bootstrap': True}\n",
      "mean: -0.14560, std: 0.00934, params: {'min_samples_split': 18, 'n_estimators': 2432, 'bootstrap': True}\n",
      "mean: -0.18770, std: 0.00964, params: {'min_samples_split': 19, 'n_estimators': 2178, 'bootstrap': False}\n",
      "mean: -0.14346, std: 0.00982, params: {'min_samples_split': 12, 'n_estimators': 4660, 'bootstrap': True}\n",
      "mean: -0.14604, std: 0.00905, params: {'min_samples_split': 19, 'n_estimators': 592, 'bootstrap': True}\n",
      "mean: -0.18809, std: 0.01050, params: {'min_samples_split': 17, 'n_estimators': 1978, 'bootstrap': False}\n",
      "mean: -0.14562, std: 0.00935, params: {'min_samples_split': 18, 'n_estimators': 2459, 'bootstrap': True}\n",
      "mean: -0.14394, std: 0.00963, params: {'min_samples_split': 13, 'n_estimators': 2544, 'bootstrap': True}\n",
      "mean: -0.19136, std: 0.01072, params: {'min_samples_split': 11, 'n_estimators': 3485, 'bootstrap': False}\n",
      "mean: -0.14207, std: 0.01030, params: {'min_samples_split': 4, 'n_estimators': 3957, 'bootstrap': True}\n",
      "mean: -0.14326, std: 0.00977, params: {'min_samples_split': 11, 'n_estimators': 3011, 'bootstrap': True}\n",
      "mean: -0.19153, std: 0.01148, params: {'min_samples_split': 10, 'n_estimators': 216, 'bootstrap': False}\n",
      "mean: -0.14258, std: 0.01010, params: {'min_samples_split': 8, 'n_estimators': 4251, 'bootstrap': True}\n",
      "mean: -0.19088, std: 0.01095, params: {'min_samples_split': 13, 'n_estimators': 1576, 'bootstrap': False}\n",
      "mean: -0.14320, std: 0.00939, params: {'min_samples_split': 11, 'n_estimators': 1046, 'bootstrap': True}\n",
      "mean: -0.19044, std: 0.01083, params: {'min_samples_split': 14, 'n_estimators': 578, 'bootstrap': False}\n",
      "mean: -0.19111, std: 0.01145, params: {'min_samples_split': 12, 'n_estimators': 1218, 'bootstrap': False}\n",
      "mean: -0.19100, std: 0.01144, params: {'min_samples_split': 12, 'n_estimators': 4442, 'bootstrap': False}\n",
      "mean: -0.19173, std: 0.01174, params: {'min_samples_split': 7, 'n_estimators': 2299, 'bootstrap': False}\n",
      "mean: -0.14225, std: 0.01028, params: {'min_samples_split': 6, 'n_estimators': 3930, 'bootstrap': True}\n",
      "mean: -0.19133, std: 0.01150, params: {'min_samples_split': 6, 'n_estimators': 1481, 'bootstrap': False}\n",
      "mean: -0.19137, std: 0.01072, params: {'min_samples_split': 11, 'n_estimators': 2289, 'bootstrap': False}\n",
      "mean: -0.19181, std: 0.01113, params: {'min_samples_split': 5, 'n_estimators': 2740, 'bootstrap': False}\n",
      "mean: -0.19035, std: 0.01088, params: {'min_samples_split': 14, 'n_estimators': 4831, 'bootstrap': False}\n",
      "mean: -0.14225, std: 0.01026, params: {'min_samples_split': 6, 'n_estimators': 4624, 'bootstrap': True}\n",
      "mean: -0.19199, std: 0.01102, params: {'min_samples_split': 5, 'n_estimators': 693, 'bootstrap': False}\n",
      "mean: -0.18807, std: 0.01050, params: {'min_samples_split': 17, 'n_estimators': 2161, 'bootstrap': False}\n",
      "mean: -0.19098, std: 0.01144, params: {'min_samples_split': 12, 'n_estimators': 3922, 'bootstrap': False}\n",
      "mean: -0.14318, std: 0.00981, params: {'min_samples_split': 11, 'n_estimators': 4634, 'bootstrap': True}\n",
      "mean: -0.14292, std: 0.00974, params: {'min_samples_split': 9, 'n_estimators': 1966, 'bootstrap': True}\n",
      "mean: -0.18880, std: 0.00996, params: {'min_samples_split': 16, 'n_estimators': 3262, 'bootstrap': False}\n",
      "mean: -0.19175, std: 0.01175, params: {'min_samples_split': 7, 'n_estimators': 1971, 'bootstrap': False}\n",
      "mean: -0.18932, std: 0.01053, params: {'min_samples_split': 15, 'n_estimators': 2078, 'bootstrap': False}\n",
      "mean: -0.14602, std: 0.00937, params: {'min_samples_split': 19, 'n_estimators': 2977, 'bootstrap': True}\n",
      "mean: -0.14608, std: 0.00906, params: {'min_samples_split': 19, 'n_estimators': 1614, 'bootstrap': True}\n",
      "mean: -0.18879, std: 0.00995, params: {'min_samples_split': 16, 'n_estimators': 3836, 'bootstrap': False}\n",
      "mean: -0.14552, std: 0.00944, params: {'min_samples_split': 18, 'n_estimators': 4783, 'bootstrap': True}\n",
      "mean: -0.14316, std: 0.00980, params: {'min_samples_split': 11, 'n_estimators': 4758, 'bootstrap': True}\n",
      "mean: -0.14213, std: 0.01037, params: {'min_samples_split': 5, 'n_estimators': 3617, 'bootstrap': True}\n",
      "mean: -0.14476, std: 0.00959, params: {'min_samples_split': 16, 'n_estimators': 4656, 'bootstrap': True}\n",
      "mean: -0.14483, std: 0.00957, params: {'min_samples_split': 16, 'n_estimators': 3106, 'bootstrap': True}\n",
      "mean: -0.19179, std: 0.01131, params: {'min_samples_split': 4, 'n_estimators': 3470, 'bootstrap': False}\n",
      "mean: -0.14259, std: 0.00991, params: {'min_samples_split': 7, 'n_estimators': 1311, 'bootstrap': True}\n",
      "mean: -0.14442, std: 0.00886, params: {'min_samples_split': 15, 'n_estimators': 395, 'bootstrap': True}\n",
      "mean: -0.14300, std: 0.00996, params: {'min_samples_split': 10, 'n_estimators': 4511, 'bootstrap': True}\n",
      "mean: -0.19143, std: 0.01137, params: {'min_samples_split': 10, 'n_estimators': 1752, 'bootstrap': False}\n",
      "mean: -0.14256, std: 0.01009, params: {'min_samples_split': 8, 'n_estimators': 4798, 'bootstrap': True}\n",
      "mean: -0.14207, std: 0.01022, params: {'min_samples_split': 2, 'n_estimators': 2200, 'bootstrap': True}\n",
      "mean: -0.14280, std: 0.01004, params: {'min_samples_split': 9, 'n_estimators': 3358, 'bootstrap': True}\n",
      "mean: -0.19260, std: 0.01188, params: {'min_samples_split': 8, 'n_estimators': 3458, 'bootstrap': False}\n",
      "mean: -0.14522, std: 0.00888, params: {'min_samples_split': 15, 'n_estimators': 62, 'bootstrap': True}\n",
      "mean: -0.19209, std: 0.01102, params: {'min_samples_split': 3, 'n_estimators': 4468, 'bootstrap': False}\n",
      "mean: -0.19236, std: 0.01059, params: {'min_samples_split': 3, 'n_estimators': 298, 'bootstrap': False}\n",
      "mean: -0.19090, std: 0.01099, params: {'min_samples_split': 13, 'n_estimators': 3179, 'bootstrap': False}\n",
      "mean: -0.19145, std: 0.01135, params: {'min_samples_split': 10, 'n_estimators': 4365, 'bootstrap': False}\n",
      "mean: -0.14319, std: 0.00935, params: {'min_samples_split': 11, 'n_estimators': 965, 'bootstrap': True}\n",
      "mean: -0.14212, std: 0.01026, params: {'min_samples_split': 4, 'n_estimators': 2812, 'bootstrap': True}\n",
      "mean: -0.14247, std: 0.01008, params: {'min_samples_split': 7, 'n_estimators': 2561, 'bootstrap': True}\n",
      " \n",
      "Best valid score (RMSLE):  0.142066632321\n",
      "Full data training score:  0.051684129775\n",
      "{'min_samples_split': 2, 'n_estimators': 2200, 'bootstrap': True}\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_def = RandomForestRegressor(random_state=666, n_jobs=-1)\n",
    "params = {'min_samples_split': scipy.stats.randint(low=2, high=20), 'n_estimators': scipy.stats.randint(low=50, high=5000), 'bootstrap': [True, False]}\n",
    "np.random.seed(666)\n",
    "rf_model = my.make_model(features, prices, rf_def, params, cv=kf, grid_type='random', n_iter=100, n_jobs=-1)\n",
    "np.random.seed(666)\n",
    "rf_log_model = my.make_model(features, logSalePrice, rf_def, params, cv=kf, y_type='log1p', grid_type='random', n_iter=100, n_jobs=-1)\n",
    "\n",
    "scores = pd.DataFrame([['RandomForest', str(rf_model.best_params_), -rf_model.best_score_]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores = model_scores.append(scores)\n",
    "scores = pd.DataFrame([['RandomForest', str(rf_log_model.best_params_), -rf_log_model.best_score_]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores_log = model_scores_log.append(scores)\n",
    "\n",
    "my.fit_submit(test_features, test_id, rf_model, '../data/submissions/rf.csv')\n",
    "my.fit_submit(test_features, test_id, rf_log_model, '../data/submissions/rf_log.csv', price_type='log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating/finding an Extra Trees model, both for original SalesPrice and for the log-transformed variable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 61.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 153.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 175.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.14780, std: 0.00971, params: {'min_samples_split': 4, 'n_estimators': 2000, 'bootstrap': True}\n",
      "mean: -0.14876, std: 0.00969, params: {'min_samples_split': 8, 'n_estimators': 2043, 'bootstrap': True}\n",
      "mean: -0.14811, std: 0.01002, params: {'min_samples_split': 6, 'n_estimators': 1519, 'bootstrap': True}\n",
      "mean: -0.14930, std: 0.00982, params: {'min_samples_split': 16, 'n_estimators': 2835, 'bootstrap': False}\n",
      "mean: -0.15026, std: 0.00980, params: {'min_samples_split': 18, 'n_estimators': 3168, 'bootstrap': False}\n",
      "mean: -0.14929, std: 0.00966, params: {'min_samples_split': 9, 'n_estimators': 3191, 'bootstrap': True}\n",
      "mean: -0.15165, std: 0.00942, params: {'min_samples_split': 14, 'n_estimators': 4097, 'bootstrap': True}\n",
      "mean: -0.14723, std: 0.00981, params: {'min_samples_split': 7, 'n_estimators': 935, 'bootstrap': False}\n",
      "mean: -0.15113, std: 0.00948, params: {'min_samples_split': 13, 'n_estimators': 4170, 'bootstrap': True}\n",
      "mean: -0.14807, std: 0.01003, params: {'min_samples_split': 6, 'n_estimators': 674, 'bootstrap': True}\n",
      "mean: -0.14823, std: 0.00990, params: {'min_samples_split': 6, 'n_estimators': 3984, 'bootstrap': True}\n",
      "mean: -0.15342, std: 0.00932, params: {'min_samples_split': 17, 'n_estimators': 2006, 'bootstrap': True}\n",
      "mean: -0.14876, std: 0.01003, params: {'min_samples_split': 7, 'n_estimators': 604, 'bootstrap': True}\n",
      "mean: -0.14913, std: 0.00995, params: {'min_samples_split': 15, 'n_estimators': 4819, 'bootstrap': False}\n",
      "mean: -0.14772, std: 0.01004, params: {'min_samples_split': 2, 'n_estimators': 192, 'bootstrap': True}\n",
      "mean: -0.14875, std: 0.00968, params: {'min_samples_split': 8, 'n_estimators': 3826, 'bootstrap': True}\n",
      "mean: -0.14771, std: 0.00973, params: {'min_samples_split': 4, 'n_estimators': 4651, 'bootstrap': True}\n",
      "mean: -0.14682, std: 0.01032, params: {'min_samples_split': 4, 'n_estimators': 897, 'bootstrap': False}\n",
      "mean: -0.14883, std: 0.00980, params: {'min_samples_split': 8, 'n_estimators': 2253, 'bootstrap': True}\n",
      "mean: -0.14882, std: 0.00975, params: {'min_samples_split': 8, 'n_estimators': 3131, 'bootstrap': True}\n",
      "mean: -0.14912, std: 0.00964, params: {'min_samples_split': 15, 'n_estimators': 1119, 'bootstrap': False}\n",
      "mean: -0.14818, std: 0.00997, params: {'min_samples_split': 6, 'n_estimators': 1585, 'bootstrap': True}\n",
      "mean: -0.15122, std: 0.00938, params: {'min_samples_split': 13, 'n_estimators': 2041, 'bootstrap': True}\n",
      "mean: -0.15340, std: 0.00929, params: {'min_samples_split': 17, 'n_estimators': 1733, 'bootstrap': True}\n",
      "mean: -0.15345, std: 0.00931, params: {'min_samples_split': 17, 'n_estimators': 3377, 'bootstrap': True}\n",
      "mean: -0.14725, std: 0.01040, params: {'min_samples_split': 5, 'n_estimators': 1207, 'bootstrap': False}\n",
      "mean: -0.14710, std: 0.01003, params: {'min_samples_split': 7, 'n_estimators': 2935, 'bootstrap': False}\n",
      "mean: -0.15356, std: 0.00855, params: {'min_samples_split': 18, 'n_estimators': 195, 'bootstrap': True}\n",
      "mean: -0.14780, std: 0.01007, params: {'min_samples_split': 12, 'n_estimators': 2526, 'bootstrap': False}\n",
      "mean: -0.15340, std: 0.00930, params: {'min_samples_split': 17, 'n_estimators': 1884, 'bootstrap': True}\n",
      "mean: -0.14749, std: 0.01004, params: {'min_samples_split': 3, 'n_estimators': 4441, 'bootstrap': True}\n",
      "mean: -0.14850, std: 0.01015, params: {'min_samples_split': 14, 'n_estimators': 3972, 'bootstrap': False}\n",
      "mean: -0.14811, std: 0.00994, params: {'min_samples_split': 4, 'n_estimators': 718, 'bootstrap': True}\n",
      "mean: -0.14874, std: 0.00980, params: {'min_samples_split': 7, 'n_estimators': 1402, 'bootstrap': True}\n",
      "mean: -0.14709, std: 0.01001, params: {'min_samples_split': 7, 'n_estimators': 2723, 'bootstrap': False}\n",
      "mean: -0.14964, std: 0.00967, params: {'min_samples_split': 10, 'n_estimators': 1957, 'bootstrap': True}\n",
      "mean: -0.14795, std: 0.01000, params: {'min_samples_split': 6, 'n_estimators': 594, 'bootstrap': True}\n",
      "mean: -0.14703, std: 0.01032, params: {'min_samples_split': 6, 'n_estimators': 4282, 'bootstrap': False}\n",
      "mean: -0.14681, std: 0.01051, params: {'min_samples_split': 4, 'n_estimators': 3898, 'bootstrap': False}\n",
      "mean: -0.14694, std: 0.01033, params: {'min_samples_split': 2, 'n_estimators': 1066, 'bootstrap': False}\n",
      "mean: -0.14702, std: 0.01032, params: {'min_samples_split': 8, 'n_estimators': 4097, 'bootstrap': False}\n",
      "mean: -0.14711, std: 0.00995, params: {'min_samples_split': 7, 'n_estimators': 2060, 'bootstrap': False}\n",
      "mean: -0.14898, std: 0.00950, params: {'min_samples_split': 9, 'n_estimators': 513, 'bootstrap': True}\n",
      "mean: -0.15398, std: 0.00932, params: {'min_samples_split': 18, 'n_estimators': 2432, 'bootstrap': True}\n",
      "mean: -0.15095, std: 0.00990, params: {'min_samples_split': 19, 'n_estimators': 2178, 'bootstrap': False}\n",
      "mean: -0.15072, std: 0.00943, params: {'min_samples_split': 12, 'n_estimators': 4660, 'bootstrap': True}\n",
      "mean: -0.15464, std: 0.00938, params: {'min_samples_split': 19, 'n_estimators': 592, 'bootstrap': True}\n",
      "mean: -0.14990, std: 0.01001, params: {'min_samples_split': 17, 'n_estimators': 1978, 'bootstrap': False}\n",
      "mean: -0.15396, std: 0.00932, params: {'min_samples_split': 18, 'n_estimators': 2459, 'bootstrap': True}\n",
      "mean: -0.15117, std: 0.00952, params: {'min_samples_split': 13, 'n_estimators': 2544, 'bootstrap': True}\n",
      "mean: -0.14748, std: 0.01025, params: {'min_samples_split': 11, 'n_estimators': 3485, 'bootstrap': False}\n",
      "mean: -0.14772, std: 0.00974, params: {'min_samples_split': 4, 'n_estimators': 3957, 'bootstrap': True}\n",
      "mean: -0.15022, std: 0.00951, params: {'min_samples_split': 11, 'n_estimators': 3011, 'bootstrap': True}\n",
      "mean: -0.14785, std: 0.00982, params: {'min_samples_split': 10, 'n_estimators': 216, 'bootstrap': False}\n",
      "mean: -0.14878, std: 0.00967, params: {'min_samples_split': 8, 'n_estimators': 4251, 'bootstrap': True}\n",
      "mean: -0.14833, std: 0.01017, params: {'min_samples_split': 13, 'n_estimators': 1576, 'bootstrap': False}\n",
      "mean: -0.15005, std: 0.00951, params: {'min_samples_split': 11, 'n_estimators': 1046, 'bootstrap': True}\n",
      "mean: -0.14868, std: 0.01014, params: {'min_samples_split': 14, 'n_estimators': 578, 'bootstrap': False}\n",
      "mean: -0.14791, std: 0.01014, params: {'min_samples_split': 12, 'n_estimators': 1218, 'bootstrap': False}\n",
      "mean: -0.14785, std: 0.01006, params: {'min_samples_split': 12, 'n_estimators': 4442, 'bootstrap': False}\n",
      "mean: -0.14711, std: 0.00992, params: {'min_samples_split': 7, 'n_estimators': 2299, 'bootstrap': False}\n",
      "mean: -0.14822, std: 0.00991, params: {'min_samples_split': 6, 'n_estimators': 3930, 'bootstrap': True}\n",
      "mean: -0.14716, std: 0.01047, params: {'min_samples_split': 6, 'n_estimators': 1481, 'bootstrap': False}\n",
      "mean: -0.14745, std: 0.01021, params: {'min_samples_split': 11, 'n_estimators': 2289, 'bootstrap': False}\n",
      "mean: -0.14711, std: 0.01045, params: {'min_samples_split': 5, 'n_estimators': 2740, 'bootstrap': False}\n",
      "mean: -0.14857, std: 0.01016, params: {'min_samples_split': 14, 'n_estimators': 4831, 'bootstrap': False}\n",
      "mean: -0.14825, std: 0.00991, params: {'min_samples_split': 6, 'n_estimators': 4624, 'bootstrap': True}\n",
      "mean: -0.14711, std: 0.00994, params: {'min_samples_split': 5, 'n_estimators': 693, 'bootstrap': False}\n",
      "mean: -0.14987, std: 0.01003, params: {'min_samples_split': 17, 'n_estimators': 2161, 'bootstrap': False}\n",
      "mean: -0.14779, std: 0.01007, params: {'min_samples_split': 12, 'n_estimators': 3922, 'bootstrap': False}\n",
      "mean: -0.15013, std: 0.00950, params: {'min_samples_split': 11, 'n_estimators': 4634, 'bootstrap': True}\n",
      "mean: -0.14905, std: 0.00961, params: {'min_samples_split': 9, 'n_estimators': 1966, 'bootstrap': True}\n",
      "mean: -0.14929, std: 0.00987, params: {'min_samples_split': 16, 'n_estimators': 3262, 'bootstrap': False}\n",
      "mean: -0.14717, std: 0.00994, params: {'min_samples_split': 7, 'n_estimators': 1971, 'bootstrap': False}\n",
      "mean: -0.14895, std: 0.00981, params: {'min_samples_split': 15, 'n_estimators': 2078, 'bootstrap': False}\n",
      "mean: -0.15459, std: 0.00921, params: {'min_samples_split': 19, 'n_estimators': 2977, 'bootstrap': True}\n",
      "mean: -0.15465, std: 0.00919, params: {'min_samples_split': 19, 'n_estimators': 1614, 'bootstrap': True}\n",
      "mean: -0.14935, std: 0.00991, params: {'min_samples_split': 16, 'n_estimators': 3836, 'bootstrap': False}\n",
      "mean: -0.15402, std: 0.00938, params: {'min_samples_split': 18, 'n_estimators': 4783, 'bootstrap': True}\n",
      "mean: -0.15011, std: 0.00951, params: {'min_samples_split': 11, 'n_estimators': 4758, 'bootstrap': True}\n",
      "mean: -0.14784, std: 0.00985, params: {'min_samples_split': 5, 'n_estimators': 3617, 'bootstrap': True}\n",
      "mean: -0.15287, std: 0.00939, params: {'min_samples_split': 16, 'n_estimators': 4656, 'bootstrap': True}\n",
      "mean: -0.15291, std: 0.00943, params: {'min_samples_split': 16, 'n_estimators': 3106, 'bootstrap': True}\n",
      "mean: -0.14674, std: 0.01051, params: {'min_samples_split': 4, 'n_estimators': 3470, 'bootstrap': False}\n",
      "mean: -0.14880, std: 0.00974, params: {'min_samples_split': 7, 'n_estimators': 1311, 'bootstrap': True}\n",
      "mean: -0.15274, std: 0.00987, params: {'min_samples_split': 15, 'n_estimators': 395, 'bootstrap': True}\n",
      "mean: -0.14970, std: 0.00963, params: {'min_samples_split': 10, 'n_estimators': 4511, 'bootstrap': True}\n",
      "mean: -0.14720, std: 0.00996, params: {'min_samples_split': 10, 'n_estimators': 1752, 'bootstrap': False}\n",
      "mean: -0.14874, std: 0.00969, params: {'min_samples_split': 8, 'n_estimators': 4798, 'bootstrap': True}\n",
      "mean: -0.14757, std: 0.01011, params: {'min_samples_split': 2, 'n_estimators': 2200, 'bootstrap': True}\n",
      "mean: -0.14926, std: 0.00966, params: {'min_samples_split': 9, 'n_estimators': 3358, 'bootstrap': True}\n",
      "mean: -0.14700, std: 0.01044, params: {'min_samples_split': 8, 'n_estimators': 3458, 'bootstrap': False}\n",
      "mean: -0.15274, std: 0.00942, params: {'min_samples_split': 15, 'n_estimators': 62, 'bootstrap': True}\n",
      "mean: -0.14692, std: 0.01051, params: {'min_samples_split': 3, 'n_estimators': 4468, 'bootstrap': False}\n",
      "mean: -0.14757, std: 0.01082, params: {'min_samples_split': 3, 'n_estimators': 298, 'bootstrap': False}\n",
      "mean: -0.14821, std: 0.01019, params: {'min_samples_split': 13, 'n_estimators': 3179, 'bootstrap': False}\n",
      "mean: -0.14730, std: 0.01012, params: {'min_samples_split': 10, 'n_estimators': 4365, 'bootstrap': False}\n",
      "mean: -0.15004, std: 0.00954, params: {'min_samples_split': 11, 'n_estimators': 965, 'bootstrap': True}\n",
      "mean: -0.14773, std: 0.00979, params: {'min_samples_split': 4, 'n_estimators': 2812, 'bootstrap': True}\n",
      "mean: -0.14860, std: 0.00980, params: {'min_samples_split': 7, 'n_estimators': 2561, 'bootstrap': True}\n",
      " \n",
      "Best valid score (RMSLE):  0.146738513814\n",
      "Full data training score:  0.0139428740508\n",
      "{'min_samples_split': 4, 'n_estimators': 3470, 'bootstrap': False}\n",
      "\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 152.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 174.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.14367, std: 0.00842, params: {'min_samples_split': 4, 'n_estimators': 2000, 'bootstrap': True}\n",
      "mean: -0.14462, std: 0.00878, params: {'min_samples_split': 8, 'n_estimators': 2043, 'bootstrap': True}\n",
      "mean: -0.14392, std: 0.00853, params: {'min_samples_split': 6, 'n_estimators': 1519, 'bootstrap': True}\n",
      "mean: -0.14614, std: 0.00977, params: {'min_samples_split': 16, 'n_estimators': 2835, 'bootstrap': False}\n",
      "mean: -0.14685, std: 0.00982, params: {'min_samples_split': 18, 'n_estimators': 3168, 'bootstrap': False}\n",
      "mean: -0.14494, std: 0.00848, params: {'min_samples_split': 9, 'n_estimators': 3191, 'bootstrap': True}\n",
      "mean: -0.14703, std: 0.00838, params: {'min_samples_split': 14, 'n_estimators': 4097, 'bootstrap': True}\n",
      "mean: -0.14428, std: 0.00987, params: {'min_samples_split': 7, 'n_estimators': 935, 'bootstrap': False}\n",
      "mean: -0.14657, std: 0.00848, params: {'min_samples_split': 13, 'n_estimators': 4170, 'bootstrap': True}\n",
      "mean: -0.14396, std: 0.00814, params: {'min_samples_split': 6, 'n_estimators': 674, 'bootstrap': True}\n",
      "mean: -0.14413, std: 0.00843, params: {'min_samples_split': 6, 'n_estimators': 3984, 'bootstrap': True}\n",
      "mean: -0.14855, std: 0.00840, params: {'min_samples_split': 17, 'n_estimators': 2006, 'bootstrap': True}\n",
      "mean: -0.14445, std: 0.00865, params: {'min_samples_split': 7, 'n_estimators': 604, 'bootstrap': True}\n",
      "mean: -0.14565, std: 0.01002, params: {'min_samples_split': 15, 'n_estimators': 4819, 'bootstrap': False}\n",
      "mean: -0.14451, std: 0.00844, params: {'min_samples_split': 2, 'n_estimators': 192, 'bootstrap': True}\n",
      "mean: -0.14463, std: 0.00873, params: {'min_samples_split': 8, 'n_estimators': 3826, 'bootstrap': True}\n",
      "mean: -0.14369, std: 0.00865, params: {'min_samples_split': 4, 'n_estimators': 4651, 'bootstrap': True}\n",
      "mean: -0.14422, std: 0.01035, params: {'min_samples_split': 4, 'n_estimators': 897, 'bootstrap': False}\n",
      "mean: -0.14466, std: 0.00877, params: {'min_samples_split': 8, 'n_estimators': 2253, 'bootstrap': True}\n",
      "mean: -0.14472, std: 0.00877, params: {'min_samples_split': 8, 'n_estimators': 3131, 'bootstrap': True}\n",
      "mean: -0.14588, std: 0.00999, params: {'min_samples_split': 15, 'n_estimators': 1119, 'bootstrap': False}\n",
      "mean: -0.14399, std: 0.00852, params: {'min_samples_split': 6, 'n_estimators': 1585, 'bootstrap': True}\n",
      "mean: -0.14653, std: 0.00849, params: {'min_samples_split': 13, 'n_estimators': 2041, 'bootstrap': True}\n",
      "mean: -0.14858, std: 0.00837, params: {'min_samples_split': 17, 'n_estimators': 1733, 'bootstrap': True}\n",
      "mean: -0.14859, std: 0.00844, params: {'min_samples_split': 17, 'n_estimators': 3377, 'bootstrap': True}\n",
      "mean: -0.14406, std: 0.01036, params: {'min_samples_split': 5, 'n_estimators': 1207, 'bootstrap': False}\n",
      "mean: -0.14425, std: 0.00957, params: {'min_samples_split': 7, 'n_estimators': 2935, 'bootstrap': False}\n",
      "mean: -0.14870, std: 0.00793, params: {'min_samples_split': 18, 'n_estimators': 195, 'bootstrap': True}\n",
      "mean: -0.14468, std: 0.01029, params: {'min_samples_split': 12, 'n_estimators': 2526, 'bootstrap': False}\n",
      "mean: -0.14857, std: 0.00835, params: {'min_samples_split': 17, 'n_estimators': 1884, 'bootstrap': True}\n",
      "mean: -0.14360, std: 0.00877, params: {'min_samples_split': 3, 'n_estimators': 4441, 'bootstrap': True}\n",
      "mean: -0.14518, std: 0.01005, params: {'min_samples_split': 14, 'n_estimators': 3972, 'bootstrap': False}\n",
      "mean: -0.14351, std: 0.00801, params: {'min_samples_split': 4, 'n_estimators': 718, 'bootstrap': True}\n",
      "mean: -0.14445, std: 0.00864, params: {'min_samples_split': 7, 'n_estimators': 1402, 'bootstrap': True}\n",
      "mean: -0.14425, std: 0.00956, params: {'min_samples_split': 7, 'n_estimators': 2723, 'bootstrap': False}\n",
      "mean: -0.14531, std: 0.00858, params: {'min_samples_split': 10, 'n_estimators': 1957, 'bootstrap': True}\n",
      "mean: -0.14402, std: 0.00810, params: {'min_samples_split': 6, 'n_estimators': 594, 'bootstrap': True}\n",
      "mean: -0.14445, std: 0.00988, params: {'min_samples_split': 6, 'n_estimators': 4282, 'bootstrap': False}\n",
      "mean: -0.14402, std: 0.01015, params: {'min_samples_split': 4, 'n_estimators': 3898, 'bootstrap': False}\n",
      "mean: -0.14420, std: 0.01010, params: {'min_samples_split': 2, 'n_estimators': 1066, 'bootstrap': False}\n",
      "mean: -0.14432, std: 0.00969, params: {'min_samples_split': 8, 'n_estimators': 4097, 'bootstrap': False}\n",
      "mean: -0.14429, std: 0.00971, params: {'min_samples_split': 7, 'n_estimators': 2060, 'bootstrap': False}\n",
      "mean: -0.14469, std: 0.00842, params: {'min_samples_split': 9, 'n_estimators': 513, 'bootstrap': True}\n",
      "mean: -0.14909, std: 0.00852, params: {'min_samples_split': 18, 'n_estimators': 2432, 'bootstrap': True}\n",
      "mean: -0.14713, std: 0.00977, params: {'min_samples_split': 19, 'n_estimators': 2178, 'bootstrap': False}\n",
      "mean: -0.14606, std: 0.00864, params: {'min_samples_split': 12, 'n_estimators': 4660, 'bootstrap': True}\n",
      "mean: -0.14901, std: 0.00835, params: {'min_samples_split': 19, 'n_estimators': 592, 'bootstrap': True}\n",
      "mean: -0.14633, std: 0.00987, params: {'min_samples_split': 17, 'n_estimators': 1978, 'bootstrap': False}\n",
      "mean: -0.14909, std: 0.00850, params: {'min_samples_split': 18, 'n_estimators': 2459, 'bootstrap': True}\n",
      "mean: -0.14659, std: 0.00850, params: {'min_samples_split': 13, 'n_estimators': 2544, 'bootstrap': True}\n",
      "mean: -0.14481, std: 0.00962, params: {'min_samples_split': 11, 'n_estimators': 3485, 'bootstrap': False}\n",
      "mean: -0.14366, std: 0.00858, params: {'min_samples_split': 4, 'n_estimators': 3957, 'bootstrap': True}\n",
      "mean: -0.14582, std: 0.00870, params: {'min_samples_split': 11, 'n_estimators': 3011, 'bootstrap': True}\n",
      "mean: -0.14484, std: 0.00995, params: {'min_samples_split': 10, 'n_estimators': 216, 'bootstrap': False}\n",
      "mean: -0.14463, std: 0.00875, params: {'min_samples_split': 8, 'n_estimators': 4251, 'bootstrap': True}\n",
      "mean: -0.14503, std: 0.00976, params: {'min_samples_split': 13, 'n_estimators': 1576, 'bootstrap': False}\n",
      "mean: -0.14564, std: 0.00883, params: {'min_samples_split': 11, 'n_estimators': 1046, 'bootstrap': True}\n",
      "mean: -0.14520, std: 0.01008, params: {'min_samples_split': 14, 'n_estimators': 578, 'bootstrap': False}\n",
      "mean: -0.14476, std: 0.01040, params: {'min_samples_split': 12, 'n_estimators': 1218, 'bootstrap': False}\n",
      "mean: -0.14469, std: 0.01021, params: {'min_samples_split': 12, 'n_estimators': 4442, 'bootstrap': False}\n",
      "mean: -0.14425, std: 0.00960, params: {'min_samples_split': 7, 'n_estimators': 2299, 'bootstrap': False}\n",
      "mean: -0.14415, std: 0.00841, params: {'min_samples_split': 6, 'n_estimators': 3930, 'bootstrap': True}\n",
      "mean: -0.14470, std: 0.00978, params: {'min_samples_split': 6, 'n_estimators': 1481, 'bootstrap': False}\n",
      "mean: -0.14483, std: 0.00954, params: {'min_samples_split': 11, 'n_estimators': 2289, 'bootstrap': False}\n",
      "mean: -0.14412, std: 0.01027, params: {'min_samples_split': 5, 'n_estimators': 2740, 'bootstrap': False}\n",
      "mean: -0.14516, std: 0.01003, params: {'min_samples_split': 14, 'n_estimators': 4831, 'bootstrap': False}\n",
      "mean: -0.14421, std: 0.00851, params: {'min_samples_split': 6, 'n_estimators': 4624, 'bootstrap': True}\n",
      "mean: -0.14421, std: 0.01042, params: {'min_samples_split': 5, 'n_estimators': 693, 'bootstrap': False}\n",
      "mean: -0.14636, std: 0.00983, params: {'min_samples_split': 17, 'n_estimators': 2161, 'bootstrap': False}\n",
      "mean: -0.14468, std: 0.01022, params: {'min_samples_split': 12, 'n_estimators': 3922, 'bootstrap': False}\n",
      "mean: -0.14571, std: 0.00868, params: {'min_samples_split': 11, 'n_estimators': 4634, 'bootstrap': True}\n",
      "mean: -0.14480, std: 0.00842, params: {'min_samples_split': 9, 'n_estimators': 1966, 'bootstrap': True}\n",
      "mean: -0.14616, std: 0.00981, params: {'min_samples_split': 16, 'n_estimators': 3262, 'bootstrap': False}\n",
      "mean: -0.14425, std: 0.00971, params: {'min_samples_split': 7, 'n_estimators': 1971, 'bootstrap': False}\n",
      "mean: -0.14576, std: 0.01000, params: {'min_samples_split': 15, 'n_estimators': 2078, 'bootstrap': False}\n",
      "mean: -0.14949, std: 0.00862, params: {'min_samples_split': 19, 'n_estimators': 2977, 'bootstrap': True}\n",
      "mean: -0.14944, std: 0.00865, params: {'min_samples_split': 19, 'n_estimators': 1614, 'bootstrap': True}\n",
      "mean: -0.14613, std: 0.00981, params: {'min_samples_split': 16, 'n_estimators': 3836, 'bootstrap': False}\n",
      "mean: -0.14904, std: 0.00854, params: {'min_samples_split': 18, 'n_estimators': 4783, 'bootstrap': True}\n",
      "mean: -0.14571, std: 0.00871, params: {'min_samples_split': 11, 'n_estimators': 4758, 'bootstrap': True}\n",
      "mean: -0.14386, std: 0.00861, params: {'min_samples_split': 5, 'n_estimators': 3617, 'bootstrap': True}\n",
      "mean: -0.14796, std: 0.00845, params: {'min_samples_split': 16, 'n_estimators': 4656, 'bootstrap': True}\n",
      "mean: -0.14802, std: 0.00844, params: {'min_samples_split': 16, 'n_estimators': 3106, 'bootstrap': True}\n",
      "mean: -0.14400, std: 0.01013, params: {'min_samples_split': 4, 'n_estimators': 3470, 'bootstrap': False}\n",
      "mean: -0.14446, std: 0.00868, params: {'min_samples_split': 7, 'n_estimators': 1311, 'bootstrap': True}\n",
      "mean: -0.14743, std: 0.00825, params: {'min_samples_split': 15, 'n_estimators': 395, 'bootstrap': True}\n",
      "mean: -0.14525, std: 0.00854, params: {'min_samples_split': 10, 'n_estimators': 4511, 'bootstrap': True}\n",
      "mean: -0.14480, std: 0.00945, params: {'min_samples_split': 10, 'n_estimators': 1752, 'bootstrap': False}\n",
      "mean: -0.14461, std: 0.00877, params: {'min_samples_split': 8, 'n_estimators': 4798, 'bootstrap': True}\n",
      "mean: -0.14355, std: 0.00880, params: {'min_samples_split': 2, 'n_estimators': 2200, 'bootstrap': True}\n",
      "mean: -0.14491, std: 0.00842, params: {'min_samples_split': 9, 'n_estimators': 3358, 'bootstrap': True}\n",
      "mean: -0.14434, std: 0.00968, params: {'min_samples_split': 8, 'n_estimators': 3458, 'bootstrap': False}\n",
      "mean: -0.14833, std: 0.00758, params: {'min_samples_split': 15, 'n_estimators': 62, 'bootstrap': True}\n",
      "mean: -0.14421, std: 0.01016, params: {'min_samples_split': 3, 'n_estimators': 4468, 'bootstrap': False}\n",
      "mean: -0.14418, std: 0.01043, params: {'min_samples_split': 3, 'n_estimators': 298, 'bootstrap': False}\n",
      "mean: -0.14490, std: 0.00992, params: {'min_samples_split': 13, 'n_estimators': 3179, 'bootstrap': False}\n",
      "mean: -0.14471, std: 0.00958, params: {'min_samples_split': 10, 'n_estimators': 4365, 'bootstrap': False}\n",
      "mean: -0.14564, std: 0.00883, params: {'min_samples_split': 11, 'n_estimators': 965, 'bootstrap': True}\n",
      "mean: -0.14367, std: 0.00844, params: {'min_samples_split': 4, 'n_estimators': 2812, 'bootstrap': True}\n",
      "mean: -0.14458, std: 0.00856, params: {'min_samples_split': 7, 'n_estimators': 2561, 'bootstrap': True}\n",
      " \n",
      "Best valid score (RMSLE):  0.143505717077\n",
      "Full data training score:  0.058320137183\n",
      "{'min_samples_split': 4, 'n_estimators': 718, 'bootstrap': True}\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extra_def = ExtraTreesRegressor(random_state=666, n_jobs=-1)\n",
    "params = {'min_samples_split': scipy.stats.randint(low=2, high=20), 'n_estimators': scipy.stats.randint(low=50, high=5000), 'bootstrap': [True, False]}\n",
    "np.random.seed(666)\n",
    "extra_model = my.make_model(features, prices, extra_def, params, cv=kf, grid_type='random', n_iter=100, n_jobs=-1)\n",
    "np.random.seed(666)\n",
    "extra_log_model = my.make_model(features, logSalePrice, extra_def, params, cv=kf, y_type='log1p', grid_type='random', n_iter=100, n_jobs=-1)\n",
    "\n",
    "scores = pd.DataFrame([['ExtraTrees', str(extra_model.best_params_), -extra_model.best_score_]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores = model_scores.append(scores)\n",
    "scores = pd.DataFrame([['ExtraTrees', str(extra_log_model.best_params_), -extra_log_model.best_score_]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores_log = model_scores_log.append(scores)\n",
    "\n",
    "my.fit_submit(test_features, test_id, extra_model, '../data/submissions/extra.csv')\n",
    "my.fit_submit(test_features, test_id, extra_log_model, '../data/submissions/extra_log.csv', price_type='log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to combine the best models, using one averaging approach and testing against the original target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no. 1\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.04358\n",
      "Validation table score (RMSLE): 0.12472\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12461\n",
      "Validation table score (RMSLE): 0.13767\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06363\n",
      "Validation table score (RMSLE): 0.14135\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01298\n",
      "Validation table score (RMSLE): 0.13474\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05354\n",
      "Weighted validation table score (RMSLE): 0.12128\n",
      "Current weights: [ 0.26926097  0.24392732  0.2375762   0.2492355 ]\n",
      " \n",
      "Fold no. 2\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.04975\n",
      "Validation table score (RMSLE): 0.13540\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12417\n",
      "Validation table score (RMSLE): 0.14362\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06410\n",
      "Validation table score (RMSLE): 0.15593\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01173\n",
      "Validation table score (RMSLE): 0.16223\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05731\n",
      "Weighted validation table score (RMSLE): 0.13950\n",
      "Current weights: [ 0.27428979  0.25859339  0.23817772  0.2289391 ]\n",
      " \n",
      "Fold no. 3\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.04823\n",
      "Validation table score (RMSLE): 0.14084\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12251\n",
      "Validation table score (RMSLE): 0.15574\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06333\n",
      "Validation table score (RMSLE): 0.15296\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01406\n",
      "Validation table score (RMSLE): 0.15295\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05450\n",
      "Weighted validation table score (RMSLE): 0.14006\n",
      "Current weights: [ 0.26694739  0.24142256  0.24580384  0.2458262 ]\n",
      " \n",
      "Fold no. 4\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.05081\n",
      "Validation table score (RMSLE): 0.12066\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12456\n",
      "Validation table score (RMSLE): 0.14841\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06497\n",
      "Validation table score (RMSLE): 0.13457\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01331\n",
      "Validation table score (RMSLE): 0.14834\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05617\n",
      "Weighted validation table score (RMSLE): 0.12783\n",
      "Current weights: [ 0.28384585  0.23076636  0.25450253  0.23088526]\n",
      " \n",
      "Fold no. 5\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.04816\n",
      "Validation table score (RMSLE): 0.10795\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12018\n",
      "Validation table score (RMSLE): 0.14111\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06482\n",
      "Validation table score (RMSLE): 0.13508\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01428\n",
      "Validation table score (RMSLE): 0.13544\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05345\n",
      "Weighted validation table score (RMSLE): 0.11829\n",
      "Current weights: [ 0.2975271   0.2275934   0.23775426  0.23712524]\n",
      " \n",
      "Model 0\n",
      "Mean training score (RMSLE): 0.04811\n",
      "Mean validation score (RMSLE): 0.12591\n",
      "Model 1\n",
      "Mean training score (RMSLE): 0.12321\n",
      "Mean validation score (RMSLE): 0.14531\n",
      "Model 2\n",
      "Mean training score (RMSLE): 0.06417\n",
      "Mean validation score (RMSLE): 0.14398\n",
      "Model 3\n",
      "Mean training score (RMSLE): 0.01327\n",
      "Mean validation score (RMSLE): 0.14674\n",
      " \n",
      "Mean weighted training score (RMSLE): 0.05499\n",
      "Mean weighted validation score (RMSLE): 0.12939 <--\n",
      "Final weights: [ 0.27784481  0.24075645  0.24298282  0.23841592]\n",
      " \n",
      "Full data training score (RMSLE): 0.05632\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbr_def_ = gbr_model.best_estimator_\n",
    "ridge_def_ = ridge_model.best_estimator_\n",
    "rf_def_ = rf_model.best_estimator_\n",
    "extra_def_ = extra_model.best_estimator_\n",
    "models, weights, score = my.test_model_array([gbr_def_, ridge_def_, rf_def_, extra_def_], features, prices, kf)\n",
    "\n",
    "scores = pd.DataFrame([['Combinations', 'Weighted average', score]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores = model_scores.append(scores)\n",
    "\n",
    "my.fit_submit_array(test_features, test_id, models, weights, '../data/submissions/combinations_normalweights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to combine the best models, using the second averaging approach and testing against the original target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no. 1\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.04358\n",
      "Validation table score (RMSLE): 0.12472\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12461\n",
      "Validation table score (RMSLE): 0.13767\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06363\n",
      "Validation table score (RMSLE): 0.14135\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01298\n",
      "Validation table score (RMSLE): 0.13474\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05271\n",
      "Weighted validation table score (RMSLE): 0.12099\n",
      "Current weights: [ 0.28935448  0.23746757  0.2252627   0.24791524]\n",
      " \n",
      "Fold no. 2\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.04975\n",
      "Validation table score (RMSLE): 0.13540\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12417\n",
      "Validation table score (RMSLE): 0.14362\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06410\n",
      "Validation table score (RMSLE): 0.15593\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01173\n",
      "Validation table score (RMSLE): 0.16223\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05824\n",
      "Weighted validation table score (RMSLE): 0.13870\n",
      "Current weights: [ 0.29944572  0.26615441  0.22578812  0.20861175]\n",
      " \n",
      "Fold no. 3\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.04823\n",
      "Validation table score (RMSLE): 0.14084\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12251\n",
      "Validation table score (RMSLE): 0.15574\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06333\n",
      "Validation table score (RMSLE): 0.15296\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01406\n",
      "Validation table score (RMSLE): 0.15295\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05384\n",
      "Weighted validation table score (RMSLE): 0.13997\n",
      "Current weights: [ 0.28459305  0.23277088  0.24129608  0.24133999]\n",
      " \n",
      "Fold no. 4\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.05081\n",
      "Validation table score (RMSLE): 0.12066\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12456\n",
      "Validation table score (RMSLE): 0.14841\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06497\n",
      "Validation table score (RMSLE): 0.13457\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01331\n",
      "Validation table score (RMSLE): 0.14834\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05527\n",
      "Weighted validation table score (RMSLE): 0.12701\n",
      "Current weights: [ 0.31984164  0.21140483  0.2571308   0.21162273]\n",
      " \n",
      "Fold no. 5\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.04816\n",
      "Validation table score (RMSLE): 0.10795\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.12018\n",
      "Validation table score (RMSLE): 0.14111\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.06482\n",
      "Validation table score (RMSLE): 0.13508\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.01428\n",
      "Validation table score (RMSLE): 0.13544\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.05184\n",
      "Weighted validation table score (RMSLE): 0.11691\n",
      "Current weights: [ 0.3497849   0.20467619  0.22335961  0.2221793 ]\n",
      " \n",
      "Model 0\n",
      "Mean training score (RMSLE): 0.04811\n",
      "Mean validation score (RMSLE): 0.12591\n",
      "Model 1\n",
      "Mean training score (RMSLE): 0.12321\n",
      "Mean validation score (RMSLE): 0.14531\n",
      "Model 2\n",
      "Mean training score (RMSLE): 0.06417\n",
      "Mean validation score (RMSLE): 0.14398\n",
      "Model 3\n",
      "Mean training score (RMSLE): 0.01327\n",
      "Mean validation score (RMSLE): 0.14674\n",
      " \n",
      "Mean weighted training score (RMSLE): 0.05438\n",
      "Mean weighted validation score (RMSLE): 0.12872 <--\n",
      "Final weights: [ 0.30750655  0.23089029  0.23518029  0.22642288]\n",
      " \n",
      "Full data training score (RMSLE): 0.05576\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbr_def_ = gbr_model.best_estimator_\n",
    "ridge_def_ = ridge_model.best_estimator_\n",
    "rf_def_ = rf_model.best_estimator_\n",
    "extra_def_ = extra_model.best_estimator_\n",
    "models, weights, score = my.test_model_array([gbr_def_, ridge_def_, rf_def_, extra_def_], features, prices, kf, w_function='inv_sq_sum')\n",
    "\n",
    "scores = pd.DataFrame([['Combinations', 'Inv Sq Sum', score]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores = model_scores.append(scores)\n",
    "\n",
    "my.fit_submit_array(test_features, test_id, models, weights, '../data/submissions/combinations_invsqsumweights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to combine the best models - except for Gradient Boosting -, using the second averaging approach and testing against the original target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no. 1\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.12461\n",
      "Validation table score (RMSLE): 0.13767\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.06363\n",
      "Validation table score (RMSLE): 0.14135\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.01298\n",
      "Validation table score (RMSLE): 0.13474\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.06206\n",
      "Weighted validation table score (RMSLE): 0.12602\n",
      "Current weights: [ 0.33415756  0.31698322  0.34885922]\n",
      " \n",
      "Fold no. 2\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.12417\n",
      "Validation table score (RMSLE): 0.14362\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.06410\n",
      "Validation table score (RMSLE): 0.15593\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.01173\n",
      "Validation table score (RMSLE): 0.16223\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.06769\n",
      "Weighted validation table score (RMSLE): 0.14441\n",
      "Current weights: [ 0.37991976  0.32229925  0.297781  ]\n",
      " \n",
      "Fold no. 3\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.12251\n",
      "Validation table score (RMSLE): 0.15574\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.06333\n",
      "Validation table score (RMSLE): 0.15296\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.01406\n",
      "Validation table score (RMSLE): 0.15295\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.06161\n",
      "Weighted validation table score (RMSLE): 0.14257\n",
      "Current weights: [ 0.32536849  0.33728507  0.33734644]\n",
      " \n",
      "Fold no. 4\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.12456\n",
      "Validation table score (RMSLE): 0.14841\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.06497\n",
      "Validation table score (RMSLE): 0.13457\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.01331\n",
      "Validation table score (RMSLE): 0.14834\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.06345\n",
      "Weighted validation table score (RMSLE): 0.13445\n",
      "Current weights: [ 0.31081707  0.3780455   0.31113743]\n",
      " \n",
      "Fold no. 5\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.12018\n",
      "Validation table score (RMSLE): 0.14111\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.06482\n",
      "Validation table score (RMSLE): 0.13508\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.01428\n",
      "Validation table score (RMSLE): 0.13544\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.06077\n",
      "Weighted validation table score (RMSLE): 0.12768\n",
      "Current weights: [ 0.31478228  0.34351649  0.34170123]\n",
      " \n",
      "Model 0\n",
      "Mean training score (RMSLE): 0.12321\n",
      "Mean validation score (RMSLE): 0.14531\n",
      "Model 1\n",
      "Mean training score (RMSLE): 0.06417\n",
      "Mean validation score (RMSLE): 0.14398\n",
      "Model 2\n",
      "Mean training score (RMSLE): 0.01327\n",
      "Mean validation score (RMSLE): 0.14674\n",
      " \n",
      "Mean weighted training score (RMSLE): 0.06312\n",
      "Mean weighted validation score (RMSLE): 0.13502 <--\n",
      "Final weights: [ 0.33341873  0.33961373  0.32696754]\n",
      " \n",
      "Full data training score (RMSLE): 0.06382\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gbr_def_ = gbr_model.best_estimator_\n",
    "ridge_def_ = ridge_model.best_estimator_\n",
    "rf_def_ = rf_model.best_estimator_\n",
    "extra_def_ = extra_model.best_estimator_\n",
    "models, weights, score = my.test_model_array([ridge_def_, rf_def_, extra_def_], features, prices, kf, w_function='inv_sq_sum')\n",
    "\n",
    "scores = pd.DataFrame([['Combinations minus GBR', 'Inv Sq Sum', score]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores = model_scores.append(scores)\n",
    "\n",
    "my.fit_submit_array(test_features, test_id, models, weights, '../data/submissions/combinations_minusgbr_invsqsumweights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to combine the best models, using one averaging approach and testing against the log-transformed target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no. 1\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00394\n",
      "Validation table score (RMSLE): 0.00952\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05023\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.12422\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00869\n",
      "Validation table score (RMSLE): 0.00989\n",
      "Training table score (RMSLE) for correct (exp) data: 0.11254\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.12857\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00413\n",
      "Validation table score (RMSLE): 0.01073\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05292\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14013\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00457\n",
      "Validation table score (RMSLE): 0.01049\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05852\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13663\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00475\n",
      "Weighted validation table score (RMSLE): 0.00928\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06083\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.12109\n",
      "Current weights: [ 0.26584012  0.25683088  0.23564955  0.24167944]\n",
      " \n",
      "Fold no. 2\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00476\n",
      "Validation table score (RMSLE): 0.00996\n",
      "Training table score (RMSLE) for correct (exp) data: 0.06049\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.12724\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00865\n",
      "Validation table score (RMSLE): 0.01090\n",
      "Training table score (RMSLE) for correct (exp) data: 0.11197\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14086\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00408\n",
      "Validation table score (RMSLE): 0.01204\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05235\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15450\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00455\n",
      "Validation table score (RMSLE): 0.01194\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05832\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15316\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00497\n",
      "Weighted validation table score (RMSLE): 0.01049\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06355\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.13430\n",
      "Current weights: [ 0.28108563  0.25390245  0.23149045  0.23352146]\n",
      " \n",
      "Fold no. 3\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00447\n",
      "Validation table score (RMSLE): 0.01109\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05674\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14318\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00834\n",
      "Validation table score (RMSLE): 0.01170\n",
      "Training table score (RMSLE) for correct (exp) data: 0.10780\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15118\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00407\n",
      "Validation table score (RMSLE): 0.01195\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05243\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15335\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00466\n",
      "Validation table score (RMSLE): 0.01168\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05968\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15050\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00477\n",
      "Weighted validation table score (RMSLE): 0.01085\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06114\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.13956\n",
      "Current weights: [ 0.26095023  0.24714274  0.24365151  0.24825552]\n",
      " \n",
      "Fold no. 4\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00457\n",
      "Validation table score (RMSLE): 0.00920\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05787\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.11834\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00875\n",
      "Validation table score (RMSLE): 0.01025\n",
      "Training table score (RMSLE) for correct (exp) data: 0.11332\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13092\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00417\n",
      "Validation table score (RMSLE): 0.01020\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05340\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13116\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00463\n",
      "Validation table score (RMSLE): 0.01136\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05944\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14510\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00493\n",
      "Weighted validation table score (RMSLE): 0.00952\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06307\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.12182\n",
      "Current weights: [ 0.27610808  0.24957498  0.24911869  0.22519825]\n",
      " \n",
      "Fold no. 5\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00463\n",
      "Validation table score (RMSLE): 0.00807\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05910\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.10411\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00833\n",
      "Validation table score (RMSLE): 0.01246\n",
      "Training table score (RMSLE) for correct (exp) data: 0.10721\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.16945\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00416\n",
      "Validation table score (RMSLE): 0.01011\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05331\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13119\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00470\n",
      "Validation table score (RMSLE): 0.01023\n",
      "Training table score (RMSLE) for correct (exp) data: 0.06026\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13214\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00464\n",
      "Weighted validation table score (RMSLE): 0.00901\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.05924\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.11712\n",
      "Current weights: [ 0.31290186  0.19224779  0.24831507  0.24653529]\n",
      " \n",
      "Model 0\n",
      "Mean training score (RMSLE): 0.00447\n",
      "Mean validation score (RMSLE): 0.00957\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.05689\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.12342\n",
      "Model 1\n",
      "Mean training score (RMSLE): 0.00855\n",
      "Mean validation score (RMSLE): 0.01104\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.11057\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.14420\n",
      "Model 2\n",
      "Mean training score (RMSLE): 0.00412\n",
      "Mean validation score (RMSLE): 0.01101\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.05288\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.14207\n",
      "Model 3\n",
      "Mean training score (RMSLE): 0.00462\n",
      "Mean validation score (RMSLE): 0.01114\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.05924\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.14351\n",
      " \n",
      "Mean weighted training score (RMSLE): 0.00481\n",
      "Mean weighted validation score (RMSLE): 0.00983 <--\n",
      "Mean weighted training score (RMSLE) for correct (exp) data: 0.06157\n",
      "Mean weighted validation score (RMSLE) for correct (exp) data: 0.12678 <--\n",
      "Final weights: [ 0.27896708  0.23876545  0.24234888  0.23991859]\n",
      " \n",
      "Full data training score (RMSLE): 0.00490\n",
      "Full data training score (RMSLE) for correct (exp) data: 0.06283\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbr_log_def_ = gbr_log_model.best_estimator_\n",
    "ridge_log_def_ = ridge_log_model.best_estimator_\n",
    "rf_log_def_ = rf_log_model.best_estimator_\n",
    "extra_log_def_ = extra_log_model.best_estimator_\n",
    "models_log, weights_log, score_log = my.test_model_array([gbr_log_def_, ridge_log_def_, rf_log_def_, extra_log_def_], features, logSalePrice, kf, y_type='log1p')#, w_function='inv_sq_sum')\n",
    "\n",
    "scores = pd.DataFrame([['Combinations', 'Weighted average', score_log]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores_log = model_scores_log.append(scores)\n",
    "\n",
    "my.fit_submit_array(test_features, test_id, models_log, weights_log, '../data/submissions/combinations_log_normalweights.csv', price_type='log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to combine the best models, using the second averaging approach and testing against the log-transformed target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no. 1\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00394\n",
      "Validation table score (RMSLE): 0.00952\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05023\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.12422\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00869\n",
      "Validation table score (RMSLE): 0.00989\n",
      "Training table score (RMSLE) for correct (exp) data: 0.11254\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.12857\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00413\n",
      "Validation table score (RMSLE): 0.01073\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05292\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14013\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00457\n",
      "Validation table score (RMSLE): 0.01049\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05852\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13663\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00476\n",
      "Weighted validation table score (RMSLE): 0.00925\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06098\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.12076\n",
      "Current weights: [ 0.28203775  0.26324533  0.22161514  0.23310178]\n",
      " \n",
      "Fold no. 2\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00476\n",
      "Validation table score (RMSLE): 0.00996\n",
      "Training table score (RMSLE) for correct (exp) data: 0.06049\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.12724\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00865\n",
      "Validation table score (RMSLE): 0.01090\n",
      "Training table score (RMSLE) for correct (exp) data: 0.11197\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14086\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00408\n",
      "Validation table score (RMSLE): 0.01204\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05235\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15450\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00455\n",
      "Validation table score (RMSLE): 0.01194\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05832\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15316\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00498\n",
      "Weighted validation table score (RMSLE): 0.01041\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06365\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.13332\n",
      "Current weights: [ 0.31403214  0.25623037  0.21299183  0.21674566]\n",
      " \n",
      "Fold no. 3\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00447\n",
      "Validation table score (RMSLE): 0.01109\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05674\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14318\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00834\n",
      "Validation table score (RMSLE): 0.01170\n",
      "Training table score (RMSLE) for correct (exp) data: 0.10780\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15118\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00407\n",
      "Validation table score (RMSLE): 0.01195\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05243\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15335\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00466\n",
      "Validation table score (RMSLE): 0.01168\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05968\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15050\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00476\n",
      "Weighted validation table score (RMSLE): 0.01084\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06093\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.13947\n",
      "Current weights: [ 0.27219346  0.24415073  0.23730152  0.24635429]\n",
      " \n",
      "Fold no. 4\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00457\n",
      "Validation table score (RMSLE): 0.00920\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05787\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.11834\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00875\n",
      "Validation table score (RMSLE): 0.01025\n",
      "Training table score (RMSLE) for correct (exp) data: 0.11332\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13092\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00417\n",
      "Validation table score (RMSLE): 0.01020\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05340\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13116\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00463\n",
      "Validation table score (RMSLE): 0.01136\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05944\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14510\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00491\n",
      "Weighted validation table score (RMSLE): 0.00946\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06275\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.12110\n",
      "Current weights: [ 0.30336794  0.24786405  0.24695857  0.20180944]\n",
      " \n",
      "Fold no. 5\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00463\n",
      "Validation table score (RMSLE): 0.00807\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05910\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.10411\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00833\n",
      "Validation table score (RMSLE): 0.01246\n",
      "Training table score (RMSLE) for correct (exp) data: 0.10721\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.16945\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00416\n",
      "Validation table score (RMSLE): 0.01011\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05331\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13119\n",
      "-- Model 3 --\n",
      "Training table score (RMSLE): 0.00470\n",
      "Validation table score (RMSLE): 0.01023\n",
      "Training table score (RMSLE) for correct (exp) data: 0.06026\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13214\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00446\n",
      "Weighted validation table score (RMSLE): 0.00881\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.05688\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.11423\n",
      "Current weights: [ 0.38050907  0.14363869  0.23963755  0.23621469]\n",
      " \n",
      "Model 0\n",
      "Mean training score (RMSLE): 0.00447\n",
      "Mean validation score (RMSLE): 0.00957\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.05689\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.12342\n",
      "Model 1\n",
      "Mean training score (RMSLE): 0.00855\n",
      "Mean validation score (RMSLE): 0.01104\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.11057\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.14420\n",
      "Model 2\n",
      "Mean training score (RMSLE): 0.00412\n",
      "Mean validation score (RMSLE): 0.01101\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.05288\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.14207\n",
      "Model 3\n",
      "Mean training score (RMSLE): 0.00462\n",
      "Mean validation score (RMSLE): 0.01114\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.05924\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.14351\n",
      " \n",
      "Mean weighted training score (RMSLE): 0.00477\n",
      "Mean weighted validation score (RMSLE): 0.00975 <--\n",
      "Mean weighted training score (RMSLE) for correct (exp) data: 0.06104\n",
      "Mean weighted validation score (RMSLE) for correct (exp) data: 0.12578 <--\n",
      "Final weights: [ 0.3098954   0.22701376  0.23387902  0.22921183]\n",
      " \n",
      "Full data training score (RMSLE): 0.00485\n",
      "Full data training score (RMSLE) for correct (exp) data: 0.06212\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbr_log_def_ = gbr_log_model.best_estimator_\n",
    "ridge_log_def_ = ridge_log_model.best_estimator_\n",
    "rf_log_def_ = rf_log_model.best_estimator_\n",
    "extra_log_def_ = extra_log_model.best_estimator_\n",
    "models_log, weights_log, score_log = my.test_model_array([gbr_log_def_, ridge_log_def_, rf_log_def_, extra_log_def_], features, logSalePrice, kf, y_type='log1p', w_function='inv_sq_sum')\n",
    "\n",
    "scores = pd.DataFrame([['Combinations', 'Inv Sq Sum', score_log]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores_log = model_scores_log.append(scores)\n",
    "\n",
    "my.fit_submit_array(test_features, test_id, models_log, weights_log, '../data/submissions/combinations_log_invsqsumweights.csv', price_type='log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to combine the best models - except for the Gradient Boosting model -, using the second averaging approach and testing against the log-transformed target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no. 1\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00869\n",
      "Validation table score (RMSLE): 0.00989\n",
      "Training table score (RMSLE) for correct (exp) data: 0.11254\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.12857\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00413\n",
      "Validation table score (RMSLE): 0.01073\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05292\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14013\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00457\n",
      "Validation table score (RMSLE): 0.01049\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05852\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13663\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00556\n",
      "Weighted validation table score (RMSLE): 0.00955\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.07151\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.12464\n",
      "Current weights: [ 0.36665622  0.30867241  0.32467136]\n",
      " \n",
      "Fold no. 2\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00865\n",
      "Validation table score (RMSLE): 0.01090\n",
      "Training table score (RMSLE) for correct (exp) data: 0.11197\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14086\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00408\n",
      "Validation table score (RMSLE): 0.01204\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05235\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15450\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00455\n",
      "Validation table score (RMSLE): 0.01194\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05832\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15316\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00559\n",
      "Weighted validation table score (RMSLE): 0.01101\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.07195\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.14140\n",
      "Current weights: [ 0.37353116  0.31049827  0.31597058]\n",
      " \n",
      "Fold no. 3\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00834\n",
      "Validation table score (RMSLE): 0.01170\n",
      "Training table score (RMSLE) for correct (exp) data: 0.10780\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15118\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00407\n",
      "Validation table score (RMSLE): 0.01195\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05243\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15335\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00466\n",
      "Validation table score (RMSLE): 0.01168\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05968\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.15050\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00534\n",
      "Weighted validation table score (RMSLE): 0.01108\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06864\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.14251\n",
      "Current weights: [ 0.33546103  0.32605027  0.3384887 ]\n",
      " \n",
      "Fold no. 4\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00875\n",
      "Validation table score (RMSLE): 0.01025\n",
      "Training table score (RMSLE) for correct (exp) data: 0.11332\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13092\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00417\n",
      "Validation table score (RMSLE): 0.01020\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05340\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13116\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00463\n",
      "Validation table score (RMSLE): 0.01136\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05944\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.14510\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00557\n",
      "Weighted validation table score (RMSLE): 0.00997\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.07167\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.12752\n",
      "Current weights: [ 0.35580339  0.35450359  0.28969301]\n",
      " \n",
      "Fold no. 5\n",
      "-- Model 0 --\n",
      "Training table score (RMSLE): 0.00833\n",
      "Validation table score (RMSLE): 0.01246\n",
      "Training table score (RMSLE) for correct (exp) data: 0.10721\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.16945\n",
      "-- Model 1 --\n",
      "Training table score (RMSLE): 0.00416\n",
      "Validation table score (RMSLE): 0.01011\n",
      "Training table score (RMSLE) for correct (exp) data: 0.05331\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13119\n",
      "-- Model 2 --\n",
      "Training table score (RMSLE): 0.00470\n",
      "Validation table score (RMSLE): 0.01023\n",
      "Training table score (RMSLE) for correct (exp) data: 0.06026\n",
      "Validation table score (RMSLE) for correct (exp) data: 0.13214\n",
      "--\n",
      "Weighted training table score (RMSLE): 0.00500\n",
      "Weighted validation table score (RMSLE): 0.00992\n",
      "Weighted training table score (RMSLE) for correct (exp) data: 0.06411\n",
      "Weighted validation table score (RMSLE) for correct (exp) data: 0.12942\n",
      "Current weights: [ 0.23186568  0.3868298   0.38130452]\n",
      " \n",
      "Model 0\n",
      "Mean training score (RMSLE): 0.00855\n",
      "Mean validation score (RMSLE): 0.01104\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.11057\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.14420\n",
      "Model 1\n",
      "Mean training score (RMSLE): 0.00412\n",
      "Mean validation score (RMSLE): 0.01101\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.05288\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.14207\n",
      "Model 2\n",
      "Mean training score (RMSLE): 0.00462\n",
      "Mean validation score (RMSLE): 0.01114\n",
      "Mean training score (RMSLE) for correct (exp) data: 0.05924\n",
      "Mean validation score (RMSLE) for correct (exp) data: 0.14351\n",
      " \n",
      "Mean weighted training score (RMSLE): 0.00541\n",
      "Mean weighted validation score (RMSLE): 0.01031 <--\n",
      "Mean weighted training score (RMSLE) for correct (exp) data: 0.06958\n",
      "Mean weighted validation score (RMSLE) for correct (exp) data: 0.13310 <--\n",
      "Final weights: [ 0.32895558  0.33890372  0.3321407 ]\n",
      " \n",
      "Full data training score (RMSLE): 0.00543\n",
      "Full data training score (RMSLE) for correct (exp) data: 0.06986\n",
      "\n",
      "Fitting model on test data...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gbr_log_def_ = gbr_log_model.best_estimator_\n",
    "ridge_log_def_ = ridge_log_model.best_estimator_\n",
    "rf_log_def_ = rf_log_model.best_estimator_\n",
    "extra_log_def_ = extra_log_model.best_estimator_\n",
    "models_log, weights_log, score_log = my.test_model_array([ridge_log_def_, rf_log_def_, extra_log_def_], features, logSalePrice, kf, y_type='log1p', w_function='inv_sq_sum')\n",
    "\n",
    "scores = pd.DataFrame([['Combinations minus GBR', 'Inv Sq Sum', score_log]], columns=['model', 'params', 'RMSLE'])\n",
    "model_scores_log = model_scores_log.append(scores)\n",
    "\n",
    "my.fit_submit_array(test_features, test_id, models_log, weights_log, '../data/submissions/combinations_log_minusgbr_invsqsumweights.csv', price_type='log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the validation scores for the best models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 1.0885413712586016}</td>\n",
       "      <td>0.145312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBR</td>\n",
       "      <td>{'min_samples_split': 19, 'loss': 'lad', 'n_es...</td>\n",
       "      <td>0.125915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'min_samples_split': 4, 'n_estimators': 718, ...</td>\n",
       "      <td>0.143981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>{'min_samples_split': 4, 'n_estimators': 3470,...</td>\n",
       "      <td>0.146739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Combinations</td>\n",
       "      <td>Weighted average</td>\n",
       "      <td>0.129392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Combinations</td>\n",
       "      <td>Inv Sq Sum</td>\n",
       "      <td>0.128717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Combinations minus GBR</td>\n",
       "      <td>Inv Sq Sum</td>\n",
       "      <td>0.135025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                             params  \\\n",
       "0                   Ridge                      {'alpha': 1.0885413712586016}   \n",
       "0                     GBR  {'min_samples_split': 19, 'loss': 'lad', 'n_es...   \n",
       "0            RandomForest  {'min_samples_split': 4, 'n_estimators': 718, ...   \n",
       "0              ExtraTrees  {'min_samples_split': 4, 'n_estimators': 3470,...   \n",
       "0            Combinations                                   Weighted average   \n",
       "0            Combinations                                         Inv Sq Sum   \n",
       "0  Combinations minus GBR                                         Inv Sq Sum   \n",
       "\n",
       "      RMSLE  \n",
       "0  0.145312  \n",
       "0  0.125915  \n",
       "0  0.143981  \n",
       "0  0.146739  \n",
       "0  0.129392  \n",
       "0  0.128717  \n",
       "0  0.135025  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 0.53638180552121706}</td>\n",
       "      <td>0.144199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBR</td>\n",
       "      <td>{'min_samples_split': 7, 'loss': 'lad', 'n_est...</td>\n",
       "      <td>0.123418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'min_samples_split': 2, 'n_estimators': 2200,...</td>\n",
       "      <td>0.142067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>{'min_samples_split': 4, 'n_estimators': 718, ...</td>\n",
       "      <td>0.143506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Combinations</td>\n",
       "      <td>Weighted average</td>\n",
       "      <td>0.126775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Combinations</td>\n",
       "      <td>Inv Sq Sum</td>\n",
       "      <td>0.125776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Combinations minus GBR</td>\n",
       "      <td>Inv Sq Sum</td>\n",
       "      <td>0.133096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                             params  \\\n",
       "0                   Ridge                     {'alpha': 0.53638180552121706}   \n",
       "0                     GBR  {'min_samples_split': 7, 'loss': 'lad', 'n_est...   \n",
       "0            RandomForest  {'min_samples_split': 2, 'n_estimators': 2200,...   \n",
       "0              ExtraTrees  {'min_samples_split': 4, 'n_estimators': 718, ...   \n",
       "0            Combinations                                   Weighted average   \n",
       "0            Combinations                                         Inv Sq Sum   \n",
       "0  Combinations minus GBR                                         Inv Sq Sum   \n",
       "\n",
       "      RMSLE  \n",
       "0  0.144199  \n",
       "0  0.123418  \n",
       "0  0.142067  \n",
       "0  0.143506  \n",
       "0  0.126775  \n",
       "0  0.125776  \n",
       "0  0.133096  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_scores.to_csv('../data/submissions/model_scores.csv')\n",
    "model_scores_log.to_csv('../data/submissions/model_scores_log.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
